{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "All_methods_aps.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNdDu8nGe3HmBqazSoFuSRz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mcdelavega/Handling-missing-values-in-histogram-data/blob/master/All_methods_aps.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfa4KV4zu8Vg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns  \n",
        "import pandas.util.testing as tm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gacoelE_vFbA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVlOcQoEvHSW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "df = pd.read_csv(io.BytesIO(uploaded['aps_failure_training_set.csv']), sep=\",\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2XlQSaBvNRs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.replace(to_replace = 'na', value = np.NaN, inplace = True)\n",
        "df.replace(to_replace = 'neg', value = 0, inplace = True)\n",
        "df.replace(to_replace = 'pos', value = 1, inplace = True)\n",
        "\n",
        "X_all = df.drop(['class', 'aa_000', 'ab_000', 'ac_000', 'ad_000', 'ae_000', 'af_000', 'ah_000', 'ai_000', 'aj_000', 'ak_000', 'al_000', 'am_0', 'an_000', 'ao_000', 'ap_000', 'aq_000', 'ar_000', 'as_000', 'at_000', 'au_000', 'av_000', 'ax_000', 'bb_000', 'bc_000', 'bd_000', 'be_000', 'bf_000', 'bg_000', 'bh_000', 'bi_000', 'bj_000', 'bk_000', 'bl_000', 'bm_000', 'bn_000', 'bo_000', 'bp_000', 'bq_000', 'br_000', 'bs_000', 'bt_000', 'bu_000', 'bv_000', 'bx_000', 'by_000', 'bz_000', 'ca_000', 'cb_000', 'cc_000', 'cd_000', 'ce_000', 'cf_000', 'cg_000', 'ch_000', 'ci_000', 'cj_000', 'ck_000', 'cl_000', 'cm_000', 'co_000', 'cp_000', 'cq_000', 'cr_000', 'ct_000', 'cu_000', 'cv_000', 'cx_000', 'cy_000', 'cz_000', 'da_000', 'db_000', 'dc_000', 'dd_000', 'de_000', 'df_000', 'dg_000', 'dh_000', 'di_000', 'dj_000', 'dk_000', 'dl_000', 'dm_000', 'dn_000', 'do_000', 'dp_000', 'dq_000', 'dr_000', 'ds_000', 'dt_000', 'du_000', 'dv_000', 'dx_000', 'dy_000', 'dz_000', 'ea_000', 'eb_000', 'ec_00', 'ed_000', 'ef_000', 'eg_000'], axis = 1)\n",
        "y_all = df['class']\n",
        "\n",
        "train = X_all\n",
        "cols = train.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k34qJMVXvXSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#STANDARD IMPUTATIONS\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "#KNN\n",
        "knn_imputer = KNNImputer(n_neighbors=5)\n",
        "knn_imputed = knn_imputer.fit_transform(train)\n",
        "\n",
        "#transpose knn\n",
        "knn_list = list()\n",
        "knn_list.append(knn_imputed)\n",
        "\n",
        "a= {}\n",
        "cnt=0\n",
        "for i in knn_list:\n",
        "    i.transpose()\n",
        "    i= np.array(i).transpose()\n",
        "    for j in i:\n",
        "        a[cols[cnt]]=j\n",
        "        cnt=cnt+1  \n",
        "knnDF = pd.DataFrame(a)\n",
        "\n",
        "#MEAN\n",
        "mean_imputer = SimpleImputer(strategy='mean')\n",
        "mean_imputed = mean_imputer.fit_transform(train)\n",
        "#transpose mean\n",
        "mean_list = list()\n",
        "mean_list.append(mean_imputed)\n",
        "\n",
        "b= {}\n",
        "cnt=0\n",
        "for i in mean_list:\n",
        "    i.transpose()\n",
        "    i= np.array(i).transpose()\n",
        "    for j in i:\n",
        "        b[cols[cnt]]=j\n",
        "        cnt=cnt+1  \n",
        "meanDF = pd.DataFrame(b)\n",
        "\n",
        "\n",
        "#MEDIAN\n",
        "median_imputer = SimpleImputer(strategy='median')\n",
        "median_imputed = median_imputer.fit_transform(train)\n",
        "\n",
        "#transpose median\n",
        "median_list = list()\n",
        "median_list.append(median_imputed)\n",
        "\n",
        "c= {}\n",
        "cnt=0\n",
        "for i in median_list:\n",
        "    i.transpose()\n",
        "    i= np.array(i).transpose()\n",
        "    for j in i:\n",
        "        c[cols[cnt]]=j\n",
        "        cnt=cnt+1  \n",
        "medianDF = pd.DataFrame(c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SazMsI6av7ec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#KNN_1.0\n",
        "\n",
        "#PREPROCESS\n",
        "df = train\n",
        "cols = df.columns\n",
        "list_hist = list()\n",
        "temporary_list = list()\n",
        "for i, j in enumerate(cols[:-1]):\n",
        "\n",
        "  first_column = j\n",
        "  next_column = cols[i+1]\n",
        "  if  i == (len(cols)-2):\n",
        "    if first_column[0:2] == next_column[0:2]:\n",
        "      temporary_list.append(df[first_column])\n",
        "      temporary_list.append(df[next_column])\n",
        "      list_hist.append(temporary_list) \n",
        "    \n",
        "    else:\n",
        "      temporary_list.append(df[first_column])\n",
        "      list_hist.append(temporary_list) \n",
        "      #throwing the old temporary away and create a new empty \"temporary list\"\n",
        "      temporary_list = list()\n",
        "      temporary_list.append(df[next_column])\n",
        "      list_hist.append(temporary_list) \n",
        "\n",
        "  elif first_column[0:2] == next_column[0:2]:\n",
        "    temporary_list.append(df[first_column])\n",
        "\n",
        "  else: \n",
        "    #add the last column to the temporary list\n",
        "    temporary_list.append(df[first_column])\n",
        "    list_hist.append(temporary_list) \n",
        "    #throwing the old temporary away and create a new empty \"temporary list\"\n",
        "    temporary_list = list()\n",
        "\n",
        "list_hist2 = list()\n",
        "temp_list = list()\n",
        "for histogram in list_hist:\n",
        "  temp_list= list()\n",
        "  for column_index, column in enumerate(histogram):    \n",
        "    for row_index, row in enumerate(column):\n",
        "      if column_index == 0:\n",
        "        l = list()\n",
        "        l.append(row)\n",
        "        temp_list.append(l)\n",
        "      else:\n",
        "        temp_list[row_index].append(row)\n",
        "    list_hist2.append(temp_list)\n",
        "\n",
        "list_of_vectors_in_many_histograms = []\n",
        "for word in list_hist2:\n",
        "    if word not in list_of_vectors_in_many_histograms:\n",
        "        list_of_vectors_in_many_histograms.append(word)\n",
        "\n",
        "list_of_vectors_in_one_list = []\n",
        "for index, i in enumerate(list_of_vectors_in_many_histograms):\n",
        "  for index, j in enumerate(i):\n",
        "    list_of_vectors_in_one_list.append(j)\n",
        "\n",
        "from sklearn.impute import KNNImputer\n",
        "imputer = KNNImputer(n_neighbors=5)\n",
        "KNN_1 = imputer.fit_transform(list_of_vectors_in_one_list)\n",
        "\n",
        "cols = X_all.columns\n",
        "e = pd.DataFrame(KNN_1)\n",
        "e1 = pd.DataFrame(e.iloc[0:60000])\n",
        "e1= e1.reset_index(drop=True)\n",
        "e2 = pd.DataFrame(e.iloc[60000:120000])\n",
        "e2 = e2.reset_index(drop=True)\n",
        "e3 = pd.DataFrame(e.iloc[120000:180000])\n",
        "e3 = e3.reset_index(drop=True)\n",
        "e4 = pd.DataFrame(e.iloc[180000:240000])\n",
        "e4 = e4.reset_index(drop=True)\n",
        "e5 = pd.DataFrame(e.iloc[240000:300000])\n",
        "e5 = e5.reset_index(drop=True)\n",
        "e6 = pd.DataFrame(e.iloc[300000:360000])\n",
        "e6 = e6.reset_index(drop=True)\n",
        "e7 = pd.DataFrame(e.iloc[360000:420000])\n",
        "e7 = e7.reset_index(drop=True)\n",
        "\n",
        "knn_one = pd.concat([e1,e2, e3, e4, e5, e6, e7], axis=1, sort=False)\n",
        "knn_one.columns = [np.arange(0,knn_one.shape[1])]\n",
        "knn_one.columns = ['ag_000', 'ag_001', 'ag_002', 'ag_003', 'ag_004', 'ag_005', 'ag_006',\n",
        "       'ag_007', 'ag_008', 'ag_009', 'ay_000', 'ay_001', 'ay_002', 'ay_003',\n",
        "       'ay_004', 'ay_005', 'ay_006', 'ay_007', 'ay_008', 'ay_009', 'az_000',\n",
        "       'az_001', 'az_002', 'az_003', 'az_004', 'az_005', 'az_006', 'az_007',\n",
        "       'az_008', 'az_009', 'ba_000', 'ba_001', 'ba_002', 'ba_003', 'ba_004',\n",
        "       'ba_005', 'ba_006', 'ba_007', 'ba_008', 'ba_009', 'cn_000', 'cn_001',\n",
        "       'cn_002', 'cn_003', 'cn_004', 'cn_005', 'cn_006', 'cn_007', 'cn_008',\n",
        "       'cn_009', 'cs_000', 'cs_001', 'cs_002', 'cs_003', 'cs_004', 'cs_005',\n",
        "       'cs_006', 'cs_007', 'cs_008', 'cs_009', 'ee_000', 'ee_001', 'ee_002',\n",
        "       'ee_003', 'ee_004', 'ee_005', 'ee_006', 'ee_007', 'ee_008', 'ee_009']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDGPAnAzxbV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#KNN_2.0\n",
        "\n",
        "df1 = X_all.transpose()\n",
        "\n",
        "temporary_list= list()\n",
        "final_hist_list= list()\n",
        "counter=0\n",
        "for i in range(len(df1.columns)):\n",
        "    counter=0\n",
        "    temp=cols[0][:2]\n",
        "    for j in cols:\n",
        "        if temp!=j[:2]:\n",
        "            counter=counter+1\n",
        "            final_hist_list.append(temporary_list)\n",
        "            temporary_list= list()\n",
        "            temp = j[:2]\n",
        "        temporary_list.append(df1[i][j])\n",
        "    final_hist_list.append(temporary_list)\n",
        "    temporary_list=list()\n",
        "    counter=counter+1\n",
        "\n",
        "i=0\n",
        "\n",
        "last_hist_list=list()\n",
        "for i in range(counter):\n",
        "    last_hist_list.append([])\n",
        "i=0    \n",
        "\n",
        "while i < len(final_hist_list):\n",
        "    for j in range(counter):\n",
        "        last_hist_list[j].append(final_hist_list[i])\n",
        "        i=i+1 \n",
        "        \n",
        "from sklearn.impute import KNNImputer\n",
        "imputer = KNNImputer(n_neighbors=5)\n",
        "for i in range(counter):\n",
        "    last_hist_list[i] = imputer.fit_transform(last_hist_list[i])\n",
        "\n",
        "u= {}\n",
        "cnty=0\n",
        "for i in last_hist_list:\n",
        "    i.transpose()\n",
        "    i= np.array(i).transpose()\n",
        "    for j in i:\n",
        "        u[cols[cnty]]=j\n",
        "        cnty=cnty+1    \n",
        "knn_two = pd.DataFrame(u)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6aEys1exG_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Xknn_train, Xknn_test, yknn_train, yknn_test = train_test_split (knnDF, y_all, \n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 10)\n",
        "\n",
        "Xmean_train, Xmean_test, ymean_train, ymean_test = train_test_split (meanDF, y_all, \n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 10)\n",
        "\n",
        "Xmedian_train, Xmedian_test, ymedian_train, ymedian_test = train_test_split (medianDF, y_all, \n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 10)\n",
        "\n",
        "Xknn1_train, Xknn1_test, yknn1_train, yknn1_test = train_test_split (knn_one, y_all, \n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 10)\n",
        "\n",
        "Xknn2_train, Xknn2_test, yknn2_train, yknn2_test = train_test_split (knn_two, y_all, \n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPoEy2Jf4qCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "# Initialize the three models (XGBoost is initialized later)\n",
        "clf_A = LogisticRegression(solver='sag', random_state = 42, max_iter=1000000)\n",
        "clf_B = SVC(probability=True, random_state = 912, kernel='rbf')\n",
        "#Boosting refers to this general problem of producing a very accurate prediction rule \n",
        "#by combining rough and moderately inaccurate rules-of-thumb\n",
        "clf_C = xgb.XGBClassifier()\n",
        "clf_D = RandomForestClassifier(n_estimators = 128, max_depth=50)\n",
        "\n",
        "clf_A.fit(Xknn_train, yknn_train)\n",
        "clf_B.fit(Xknn_train, yknn_train)\n",
        "clf_C.fit(Xknn_train, yknn_train)\n",
        "clf_D.fit(Xknn_train, yknn_train)\n",
        "\n",
        "clf_A.fit(Xmean_train, ymean_train)\n",
        "clf_B.fit(Xmean_train, ymean_train)\n",
        "clf_C.fit(Xmean_train, ymean_train)\n",
        "clf_D.fit(Xmean_train, ymean_train)\n",
        "\n",
        "clf_A.fit(Xmedian_train, ymedian_train)\n",
        "clf_B.fit(Xmedian_train, ymedian_train)\n",
        "clf_C.fit(Xmedian_train, ymedian_train)\n",
        "clf_D.fit(Xmedian_train, ymedian_train)\n",
        "\n",
        "clf_A.fit(Xknn1_train, yknn1_train)\n",
        "clf_B.fit(Xknn1_train, yknn1_train)\n",
        "clf_C.fit(Xknn1_train, yknn1_train)\n",
        "clf_D.fit(Xknn1_train, yknn1_train)\n",
        "\n",
        "clf_A.fit(Xknn2_train, yknn2_train)\n",
        "clf_B.fit(Xknn2_train, yknn2_train)\n",
        "clf_C.fit(Xknn2_train, yknn2_train)\n",
        "clf_D.fit(Xknn2_train, yknn2_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28AscCsg5n_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
        "\n",
        "\n",
        "#********KNN******************\n",
        "\n",
        "#AUC\n",
        "knn_lr_probs = clf_A.predict_proba(Xknn_test)\n",
        "knn_svm_probs = clf_B.predict_proba(Xknn_test)\n",
        "knn_xgb_probs = clf_C.predict_proba(Xknn_test)\n",
        "knn_rf_probs = clf_D.predict_proba(Xknn_test)\n",
        "# keep probabilities for the positive outcome only\n",
        "knn_lr_probs = knn_lr_probs[:, 1]\n",
        "knn_svm_probs = knn_svm_probs[:, 1]\n",
        "knn_xgb_probs = knn_xgb_probs[:, 1]\n",
        "knn_rf_probs = knn_rf_probs[:, 1]\n",
        "# calculate scores\n",
        "knn_lr_auc = roc_auc_score(yknn_test, knn_lr_probs)\n",
        "knn_svm_auc = roc_auc_score(yknn_test, knn_svm_probs)\n",
        "knn_xgb_auc = roc_auc_score(yknn_test, knn_xgb_probs)\n",
        "knn_rf_auc = roc_auc_score(yknn_test, knn_rf_probs)\n",
        "\n",
        "# OTHER METRICS for standard KNN\n",
        "knn_lr_pred = clf_A.predict(Xknn_test)\n",
        "knn_s_pred = clf_B.predict(Xknn_test)\n",
        "knn_x_pred = clf_C.predict(Xknn_test)\n",
        "knn_rf_pred = clf_D.predict(Xknn_test)\n",
        "\n",
        "\n",
        "\n",
        "#********MEAN******************\n",
        "\n",
        "mean_lr_probs = clf_A.predict_proba(Xmean_test)\n",
        "mean_svm_probs = clf_B.predict_proba(Xmean_test)\n",
        "mean_xgb_probs = clf_C.predict_proba(Xmean_test)\n",
        "mean_rf_probs = clf_D.predict_proba(Xmean_test)\n",
        "# keep probabilities for the positive outcome only\n",
        "mean_lr_probs = mean_lr_probs[:, 1]\n",
        "mean_svm_probs = mean_svm_probs[:, 1]\n",
        "mean_xgb_probs = mean_xgb_probs[:, 1]\n",
        "mean_rf_probs = mean_rf_probs[:, 1]\n",
        "# calculate scores\n",
        "mean_lr_auc = roc_auc_score(ymean_test, mean_lr_probs)\n",
        "mean_svm_auc = roc_auc_score(ymean_test, mean_svm_probs)\n",
        "mean_xgb_auc = roc_auc_score(ymean_test, mean_xgb_probs)\n",
        "mean_rf_auc = roc_auc_score(ymean_test, mean_rf_probs)\n",
        "\n",
        "# OTHER METRICS for standard MEAN\n",
        "mean_lr_pred = clf_A.predict(Xmean_test)\n",
        "mean_s_pred = clf_B.predict(Xmean_test)\n",
        "mean_x_pred = clf_C.predict(Xmean_test)\n",
        "mean_rf_pred = clf_D.predict(Xmean_test)\n",
        "\n",
        "\n",
        "\n",
        "#********MEDIAN******************\n",
        "\n",
        "median_lr_probs = clf_A.predict_proba(Xmedian_test)\n",
        "median_svm_probs = clf_B.predict_proba(Xmedian_test)\n",
        "median_xgb_probs = clf_C.predict_proba(Xmedian_test)\n",
        "median_rf_probs = clf_D.predict_proba(Xmedian_test)\n",
        "# keep probabilities for the positive outcome only\n",
        "median_lr_probs = median_lr_probs[:, 1]\n",
        "median_svm_probs = median_svm_probs[:, 1]\n",
        "median_xgb_probs = median_xgb_probs[:, 1]\n",
        "median_rf_probs = median_rf_probs[:, 1]\n",
        "# calculate scores\n",
        "median_lr_auc = roc_auc_score(ymedian_test, median_lr_probs)\n",
        "median_svm_auc = roc_auc_score(ymedian_test, median_svm_probs)\n",
        "median_xgb_auc = roc_auc_score(ymedian_test, median_xgb_probs)\n",
        "median_rf_auc = roc_auc_score(ymedian_test, median_rf_probs)\n",
        "\n",
        "# OTHER METRICS for standard MEDIAN\n",
        "median_lr_pred = clf_A.predict(Xmedian_test)\n",
        "median_s_pred = clf_B.predict(Xmedian_test)\n",
        "median_x_pred = clf_C.predict(Xmedian_test)\n",
        "median_rf_pred = clf_D.predict(Xmedian_test)\n",
        "\n",
        "\n",
        "\n",
        "#********KNN_1.0******************\n",
        "\n",
        "#AUC\n",
        "knn1_lr_probs = clf_A.predict_proba(Xknn1_test)\n",
        "knn1_svm_probs = clf_B.predict_proba(Xknn1_test)\n",
        "knn1_xgb_probs = clf_C.predict_proba(Xknn1_test)\n",
        "knn1_rf_probs = clf_D.predict_proba(Xknn1_test)\n",
        "# keep probabilities for the positive outcome only\n",
        "knn1_lr_probs = knn1_lr_probs[:, 1]\n",
        "knn1_svm_probs = knn1_svm_probs[:, 1]\n",
        "knn1_xgb_probs = knn1_xgb_probs[:, 1]\n",
        "knn1_rf_probs = knn1_rf_probs[:, 1]\n",
        "# calculate scores\n",
        "knn1_lr_auc = roc_auc_score(yknn1_test, knn1_lr_probs)\n",
        "knn1_svm_auc = roc_auc_score(yknn1_test, knn1_svm_probs)\n",
        "knn1_xgb_auc = roc_auc_score(yknn1_test, knn1_xgb_probs)\n",
        "knn1_rf_auc = roc_auc_score(yknn1_test, knn1_rf_probs)\n",
        "\n",
        "# OTHER METRICS for standard KNN_1.0\n",
        "knn1_lr_pred = clf_A.predict(Xknn1_test)\n",
        "knn1_s_pred = clf_B.predict(Xknn1_test)\n",
        "knn1_x_pred = clf_C.predict(Xknn1_test)\n",
        "knn1_rf_pred = clf_D.predict(Xknn1_test)\n",
        "\n",
        "\n",
        "#********KNN_2.0******************\n",
        "\n",
        "#AUC\n",
        "knn2_lr_probs = clf_A.predict_proba(Xknn2_test)\n",
        "knn2_svm_probs = clf_B.predict_proba(Xknn2_test)\n",
        "knn2_xgb_probs = clf_C.predict_proba(Xknn2_test)\n",
        "knn2_rf_probs = clf_D.predict_proba(Xknn2_test)\n",
        "# keep probabilities for the positive outcome only\n",
        "knn2_lr_probs = knn2_lr_probs[:, 1]\n",
        "knn2_svm_probs = knn2_svm_probs[:, 1]\n",
        "knn2_xgb_probs = knn2_xgb_probs[:, 1]\n",
        "knn2_rf_probs = knn2_rf_probs[:, 1]\n",
        "# calculate scores\n",
        "knn2_lr_auc = roc_auc_score(yknn2_test, knn2_lr_probs)\n",
        "knn2_svm_auc = roc_auc_score(yknn2_test, knn2_svm_probs)\n",
        "knn2_xgb_auc = roc_auc_score(yknn2_test, knn2_xgb_probs)\n",
        "knn2_rf_auc = roc_auc_score(yknn2_test, knn2_rf_probs)\n",
        "\n",
        "# OTHER METRICS for standard KNN\n",
        "knn2_lr_pred = clf_A.predict(Xknn2_test)\n",
        "knn2_s_pred = clf_B.predict(Xknn2_test)\n",
        "knn2_x_pred = clf_C.predict(Xknn2_test)\n",
        "knn2_rf_pred = clf_D.predict(Xknn2_test)\n",
        "\n",
        "print ('KNN')\n",
        "print ('LOGISTIC REGRESSION')\n",
        "print('AUC score: %.3f' % (knn_lr_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn_test, knn_lr_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn_test, knn_lr_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn_test, knn_lr_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn_test, knn_lr_pred)))\n",
        "print('')\n",
        "print ('SVM')\n",
        "print('AUC score: %.3f' % (knn_svm_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn_test, knn_s_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn_test, knn_s_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn_test, knn_s_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn_test, knn_s_pred)))\n",
        "print('')\n",
        "print ('XGBOOST')\n",
        "print('AUC score: %.3f' % (knn_xgb_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn_test, knn_x_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn_test, knn_x_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn_test, knn_x_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn_test, knn_x_pred)))\n",
        "print('')\n",
        "print ('RANDOM FOREST')\n",
        "print('AUC score: %.3f' % (knn_rf_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn_test, knn_rf_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn_test, knn_rf_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn_test, knn_rf_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn_test, knn_rf_pred)))\n",
        "print('')\n",
        "print('')\n",
        "print('')\n",
        "print ('MEAN')\n",
        "print ('LOGISTIC REGRESSION')\n",
        "print('AUC score: %.3f' % (mean_lr_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymean_test, mean_lr_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymean_test, mean_lr_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymean_test, mean_lr_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymean_test, mean_lr_pred)))\n",
        "print('')\n",
        "print ('SVM')\n",
        "print('AUC score: %.3f' % (mean_svm_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymean_test, mean_s_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymean_test, mean_s_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymean_test, mean_s_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymean_test, mean_s_pred)))\n",
        "print('')\n",
        "print ('XGBOOST')\n",
        "print('AUC score: %.3f' % (mean_xgb_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymean_test, mean_x_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymean_test, mean_x_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymean_test, mean_x_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymean_test, mean_x_pred)))\n",
        "print('')\n",
        "print ('RANDOM FOREST')\n",
        "print('AUC score: %.3f' % (mean_rf_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymean_test, mean_rf_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymean_test, mean_rf_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymean_test, mean_rf_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymean_test, mean_rf_pred)))\n",
        "print('')\n",
        "print('')\n",
        "print('')\n",
        "print ('MEDIAN')\n",
        "print ('LOGISTIC REGRESSION')\n",
        "print('AUC score: %.3f' % (median_lr_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymedian_test, median_lr_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymedian_test, median_lr_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymedian_test, median_lr_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymedian_test, median_lr_pred)))\n",
        "print('')\n",
        "print ('SVM')\n",
        "print('AUC score: %.3f' % (median_svm_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymedian_test, median_s_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymedian_test, median_s_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymedian_test, median_s_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymedian_test, median_s_pred)))\n",
        "print('')\n",
        "print ('XGBOOST')\n",
        "print('AUC score: %.3f' % (median_xgb_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymedian_test, median_x_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymedian_test, median_x_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymedian_test, median_x_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymedian_test, median_x_pred)))\n",
        "print('')\n",
        "print ('RANDOM FOREST')\n",
        "print('AUC score: %.3f' % (median_rf_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymedian_test, median_rf_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymedian_test, median_rf_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymedian_test, median_rf_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymedian_test, median_rf_pred)))\n",
        "print('')\n",
        "print('')\n",
        "print('')\n",
        "print ('KNN_1.0')\n",
        "print ('LOGISTIC REGRESSION')\n",
        "print('AUC score: %.3f' % (knn1_lr_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn1_test, knn1_lr_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn1_test, knn1_lr_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn1_test, knn1_lr_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn1_test, knn1_lr_pred)))\n",
        "print('')\n",
        "print ('SVM')\n",
        "print('AUC score: %.3f' % (knn1_svm_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn1_test, knn1_s_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn1_test, knn1_s_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn1_test, knn1_s_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn1_test, knn1_s_pred)))\n",
        "print('')\n",
        "print ('XGBOOST')\n",
        "print('AUC score: %.3f' % (knn1_xgb_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn1_test, knn1_x_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn1_test, knn1_x_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn1_test, knn1_x_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn1_test, knn1_x_pred)))\n",
        "print('')\n",
        "print ('RANDOM FOREST')\n",
        "print('AUC score: %.3f' % (knn1_rf_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn1_test, knn1_rf_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn1_test, knn1_rf_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn1_test, knn1_rf_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn1_test, knn1_rf_pred)))\n",
        "print('')\n",
        "print('')\n",
        "print('')\n",
        "print ('KNN_2.0')\n",
        "print ('LOGISTIC REGRESSION')\n",
        "print('AUC score: %.3f' % (knn2_lr_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn2_test, knn2_lr_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn2_test, knn2_lr_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn2_test, knn2_lr_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn2_test, knn2_lr_pred)))\n",
        "print('')\n",
        "print ('SVM')\n",
        "print('AUC score: %.3f' % (knn2_svm_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn2_test, knn2_s_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn2_test, knn2_s_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn2_test, knn2_s_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn2_test, knn2_s_pred)))\n",
        "print('')\n",
        "print ('XGBOOST')\n",
        "print('AUC score: %.3f' % (knn2_xgb_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn2_test, knn2_x_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn2_test, knn2_x_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn2_test, knn2_x_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn2_test, knn2_x_pred)))\n",
        "print('')\n",
        "print ('RANDOM FOREST')\n",
        "print('AUC score: %.3f' % (knn2_rf_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn2_test, knn2_rf_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn2_test, knn2_rf_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn2_test, knn2_rf_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn2_test, knn2_rf_pred)))\n",
        "# summarize scores\n",
        "# print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
        "# print('SVM: ROC AUC=%.3f' % (svm_auc))\n",
        "# print('XGBoost: ROC AUC=%.3f' % (xgb_auc))\n",
        "# print('Random Forest: ROC AUC=%.3f' % (rf_auc))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}