{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "All_methods_aps_normalized.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPg6UPMzBfUFhdh6fDzni6w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mcdelavega/Handling-missing-values-in-histogram-data/blob/master/All_methods_aps_normalized.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfa4KV4zu8Vg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns  \n",
        "import pandas.util.testing as tm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gacoelE_vFbA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVlOcQoEvHSW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "df = pd.read_csv(io.BytesIO(uploaded['aps_failure_training_set.csv']), sep=\",\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2XlQSaBvNRs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.replace(to_replace = 'na', value = np.NaN, inplace = True)\n",
        "df.replace(to_replace = 'neg', value = 0, inplace = True)\n",
        "df.replace(to_replace = 'pos', value = 1, inplace = True)\n",
        "\n",
        "X_all = df.drop(['class', 'aa_000', 'ab_000', 'ac_000', 'ad_000', 'ae_000', 'af_000', 'ah_000', 'ai_000', 'aj_000', 'ak_000', 'al_000', 'am_0', 'an_000', 'ao_000', 'ap_000', 'aq_000', 'ar_000', 'as_000', 'at_000', 'au_000', 'av_000', 'ax_000', 'bb_000', 'bc_000', 'bd_000', 'be_000', 'bf_000', 'bg_000', 'bh_000', 'bi_000', 'bj_000', 'bk_000', 'bl_000', 'bm_000', 'bn_000', 'bo_000', 'bp_000', 'bq_000', 'br_000', 'bs_000', 'bt_000', 'bu_000', 'bv_000', 'bx_000', 'by_000', 'bz_000', 'ca_000', 'cb_000', 'cc_000', 'cd_000', 'ce_000', 'cf_000', 'cg_000', 'ch_000', 'ci_000', 'cj_000', 'ck_000', 'cl_000', 'cm_000', 'co_000', 'cp_000', 'cq_000', 'cr_000', 'ct_000', 'cu_000', 'cv_000', 'cx_000', 'cy_000', 'cz_000', 'da_000', 'db_000', 'dc_000', 'dd_000', 'de_000', 'df_000', 'dg_000', 'dh_000', 'di_000', 'dj_000', 'dk_000', 'dl_000', 'dm_000', 'dn_000', 'do_000', 'dp_000', 'dq_000', 'dr_000', 'ds_000', 'dt_000', 'du_000', 'dv_000', 'dx_000', 'dy_000', 'dz_000', 'ea_000', 'eb_000', 'ec_00', 'ed_000', 'ef_000', 'eg_000'], axis = 1)\n",
        "y_all = df['class']\n",
        "\n",
        "train = X_all\n",
        "cols = train.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k34qJMVXvXSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#STANDARD IMPUTATIONS\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "#KNN\n",
        "knn_imputer = KNNImputer(n_neighbors=5)\n",
        "knn_imputed = knn_imputer.fit_transform(train)\n",
        "\n",
        "#transpose knn\n",
        "knn_list = list()\n",
        "knn_list.append(knn_imputed)\n",
        "\n",
        "a= {}\n",
        "cnt=0\n",
        "for i in knn_list:\n",
        "    i.transpose()\n",
        "    i= np.array(i).transpose()\n",
        "    for j in i:\n",
        "        a[cols[cnt]]=j\n",
        "        cnt=cnt+1  \n",
        "knnDFn = pd.DataFrame(a)\n",
        "\n",
        "#MEAN\n",
        "mean_imputer = SimpleImputer(strategy='mean')\n",
        "mean_imputed = mean_imputer.fit_transform(train)\n",
        "#transpose mean\n",
        "mean_list = list()\n",
        "mean_list.append(mean_imputed)\n",
        "\n",
        "b= {}\n",
        "cnt=0\n",
        "for i in mean_list:\n",
        "    i.transpose()\n",
        "    i= np.array(i).transpose()\n",
        "    for j in i:\n",
        "        b[cols[cnt]]=j\n",
        "        cnt=cnt+1  \n",
        "meanDFn = pd.DataFrame(b)\n",
        "\n",
        "\n",
        "#MEDIAN\n",
        "median_imputer = SimpleImputer(strategy='median')\n",
        "median_imputed = median_imputer.fit_transform(train)\n",
        "\n",
        "#transpose median\n",
        "median_list = list()\n",
        "median_list.append(median_imputed)\n",
        "\n",
        "c= {}\n",
        "cnt=0\n",
        "for i in median_list:\n",
        "    i.transpose()\n",
        "    i= np.array(i).transpose()\n",
        "    for j in i:\n",
        "        c[cols[cnt]]=j\n",
        "        cnt=cnt+1  \n",
        "medianDFn = pd.DataFrame(c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEtEVWbnEE_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#THIS IS THE NORMALIZATION CELL for MEDIAN\n",
        "#CREATE A LIST OF ALL HISTOGRAMS\n",
        "median_df = medianDFn\n",
        "cols = medianDFn.columns\n",
        "medianlist_hist = list()\n",
        "mediantemporary_list = list()\n",
        "for i, j in enumerate(cols[:-1]):\n",
        "\n",
        "  first_column = j\n",
        "  next_column = cols[i+1]\n",
        "  if  i == (len(cols)-2):\n",
        "    if first_column[0:2] == next_column[0:2]:\n",
        "      mediantemporary_list.append(median_df[first_column])\n",
        "      mediantemporary_list.append(median_df[next_column])\n",
        "      medianlist_hist.append(mediantemporary_list) \n",
        "    \n",
        "    else:\n",
        "      mediantemporary_list.append(median_df[first_column])\n",
        "      medianlist_hist.append(mediantemporary_list) \n",
        "      #throwing the old temporary away and create a new empty \"temporary list\"\n",
        "      mediantemporary_list = list()\n",
        "      mediantemporary_list.append(median_df[next_column])\n",
        "      medianlist_hist.append(mediantemporary_list) \n",
        "\n",
        "  elif first_column[0:2] == next_column[0:2]:\n",
        "    mediantemporary_list.append(median_df[first_column])\n",
        "\n",
        "  else: \n",
        "    #add the last column to the temporary list\n",
        "    mediantemporary_list.append(median_df[first_column])\n",
        "    medianlist_hist.append(mediantemporary_list) \n",
        "    #throwing the old temporary away and create a new empty \"temporary list\"\n",
        "    mediantemporary_list = list()\n",
        "\n",
        "\n",
        "#CREATE NEW LIST AND REPLACE THE ITEMS WITH THEIR WEIGHTS\n",
        "medianlist_hist2 = list()\n",
        "\n",
        "for histogram in medianlist_hist:\n",
        "  sum = 0\n",
        "  for item in histogram:\n",
        "    sum += item\n",
        "  for item in histogram:\n",
        "    j=item\n",
        "    for index, itemsItem in enumerate(item):\n",
        "      if sum[index]==0:\n",
        "        j[index] = itemsItem\n",
        "      else:\n",
        "        j[index] = itemsItem/sum[index]\n",
        "  \n",
        "    medianlist_hist2.append(j)\n",
        "\n",
        "#TRANSPOSE THE LIST TO A DATAFRAME ONCE AGAIN\n",
        "medianDF = pd.DataFrame(np.transpose(medianlist_hist2),columns=cols)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6PglS_tElzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#THIS IS THE NORMALIZATION CELL for MEAN\n",
        "#CREATE A LIST OF ALL HISTOGRAMS\n",
        "mean_df = meanDFn\n",
        "cols = meanDFn.columns\n",
        "meanlist_hist = list()\n",
        "meantemporary_list = list()\n",
        "for i, j in enumerate(cols[:-1]):\n",
        "\n",
        "  first_column = j\n",
        "  next_column = cols[i+1]\n",
        "  if  i == (len(cols)-2):\n",
        "    if first_column[0:2] == next_column[0:2]:\n",
        "      meantemporary_list.append(mean_df[first_column])\n",
        "      meantemporary_list.append(mean_df[next_column])\n",
        "      meanlist_hist.append(meantemporary_list) \n",
        "    \n",
        "    else:\n",
        "      meantemporary_list.append(mean_df[first_column])\n",
        "      meanlist_hist.append(meantemporary_list) \n",
        "      #throwing the old temporary away and create a new empty \"temporary list\"\n",
        "      meantemporary_list = list()\n",
        "      meantemporary_list.append(mean_df[next_column])\n",
        "      meanlist_hist.append(meantemporary_list) \n",
        "\n",
        "  elif first_column[0:2] == next_column[0:2]:\n",
        "    meantemporary_list.append(mean_df[first_column])\n",
        "\n",
        "  else: \n",
        "    #add the last column to the temporary list\n",
        "    meantemporary_list.append(mean_df[first_column])\n",
        "    meanlist_hist.append(meantemporary_list) \n",
        "    #throwing the old temporary away and create a new empty \"temporary list\"\n",
        "    meantemporary_list = list()\n",
        "\n",
        "\n",
        "#CREATE NEW LIST AND REPLACE THE ITEMS WITH THEIR WEIGHTS\n",
        "meanlist_hist2 = list()\n",
        "\n",
        "for histogram in meanlist_hist:\n",
        "  sum = 0\n",
        "  for item in histogram:\n",
        "    sum += item\n",
        "  for item in histogram:\n",
        "    j=item\n",
        "    for index, itemsItem in enumerate(item):\n",
        "      if sum[index]==0:\n",
        "        j[index] = itemsItem\n",
        "      else:\n",
        "        j[index] = itemsItem/sum[index]\n",
        "  \n",
        "    meanlist_hist2.append(j)\n",
        "\n",
        "#TRANSPOSE THE LIST TO A DATAFRAME ONCE AGAIN\n",
        "meanDF = pd.DataFrame(np.transpose(meanlist_hist2),columns=cols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ng-rl6GiZ7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#THIS IS THE NORMALIZATION CELL for KNN\n",
        "#CREATE A LIST OF ALL HISTOGRAMS\n",
        "knn_df = knnDFn\n",
        "cols = knnDFn.columns\n",
        "knnlist_hist = list()\n",
        "knntemporary_list = list()\n",
        "for i, j in enumerate(cols[:-1]):\n",
        "\n",
        "  first_column = j\n",
        "  next_column = cols[i+1]\n",
        "  if  i == (len(cols)-2):\n",
        "    if first_column[0:2] == next_column[0:2]:\n",
        "      knntemporary_list.append(knn_df[first_column])\n",
        "      knntemporary_list.append(knn_df[next_column])\n",
        "      knnlist_hist.append(knntemporary_list) \n",
        "    \n",
        "    else:\n",
        "      knntemporary_list.append(knn_df[first_column])\n",
        "      knnlist_hist.append(knntemporary_list) \n",
        "      #throwing the old temporary away and create a new empty \"temporary list\"\n",
        "      knntemporary_list = list()\n",
        "      knntemporary_list.append(knn_df[next_column])\n",
        "      knnlist_hist.append(knntemporary_list) \n",
        "\n",
        "  elif first_column[0:2] == next_column[0:2]:\n",
        "    knntemporary_list.append(knn_df[first_column])\n",
        "\n",
        "  else: \n",
        "    #add the last column to the temporary list\n",
        "    knntemporary_list.append(knn_df[first_column])\n",
        "    knnlist_hist.append(knntemporary_list) \n",
        "    #throwing the old temporary away and create a new empty \"temporary list\"\n",
        "    knntemporary_list = list()\n",
        "\n",
        "\n",
        "#CREATE NEW LIST AND REPLACE THE ITEMS WITH THEIR WEIGHTS\n",
        "knnlist_hist2 = list()\n",
        "\n",
        "for histogram in knnlist_hist:\n",
        "  sum = 0\n",
        "  for item in histogram:\n",
        "    sum += item\n",
        "  for item in histogram:\n",
        "    j=item\n",
        "    for index, itemsItem in enumerate(item):\n",
        "      if sum[index]==0:\n",
        "        j[index] = itemsItem\n",
        "      else:\n",
        "        j[index] = itemsItem/sum[index]\n",
        "  \n",
        "    knnlist_hist2.append(j)\n",
        "\n",
        "#TRANSPOSE THE LIST TO A DATAFRAME ONCE AGAIN\n",
        "knnDF = pd.DataFrame(np.transpose(knnlist_hist2),columns=cols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcFh69tCFeGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "meanDF_scaled = scaler.fit_transform(meanDFn)\n",
        "medianDF_scaled = scaler.fit_transform(medianDFn)\n",
        "knnDF_scaled = scaler.fit_transform(knnDFn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SazMsI6av7ec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#KNN_1.0\n",
        "\n",
        "#PREPROCESS\n",
        "df = train\n",
        "cols = df.columns\n",
        "list_hist = list()\n",
        "temporary_list = list()\n",
        "for i, j in enumerate(cols[:-1]):\n",
        "\n",
        "  first_column = j\n",
        "  next_column = cols[i+1]\n",
        "  if  i == (len(cols)-2):\n",
        "    if first_column[0:2] == next_column[0:2]:\n",
        "      temporary_list.append(df[first_column])\n",
        "      temporary_list.append(df[next_column])\n",
        "      list_hist.append(temporary_list) \n",
        "    \n",
        "    else:\n",
        "      temporary_list.append(df[first_column])\n",
        "      list_hist.append(temporary_list) \n",
        "      #throwing the old temporary away and create a new empty \"temporary list\"\n",
        "      temporary_list = list()\n",
        "      temporary_list.append(df[next_column])\n",
        "      list_hist.append(temporary_list) \n",
        "\n",
        "  elif first_column[0:2] == next_column[0:2]:\n",
        "    temporary_list.append(df[first_column])\n",
        "\n",
        "  else: \n",
        "    #add the last column to the temporary list\n",
        "    temporary_list.append(df[first_column])\n",
        "    list_hist.append(temporary_list) \n",
        "    #throwing the old temporary away and create a new empty \"temporary list\"\n",
        "    temporary_list = list()\n",
        "\n",
        "list_hist2 = list()\n",
        "temp_list = list()\n",
        "for histogram in list_hist:\n",
        "  temp_list= list()\n",
        "  for column_index, column in enumerate(histogram):    \n",
        "    for row_index, row in enumerate(column):\n",
        "      if column_index == 0:\n",
        "        l = list()\n",
        "        l.append(row)\n",
        "        temp_list.append(l)\n",
        "      else:\n",
        "        temp_list[row_index].append(row)\n",
        "    list_hist2.append(temp_list)\n",
        "\n",
        "list_of_vectors_in_many_histograms = []\n",
        "for word in list_hist2:\n",
        "    if word not in list_of_vectors_in_many_histograms:\n",
        "        list_of_vectors_in_many_histograms.append(word)\n",
        "\n",
        "list_of_vectors_in_one_list = []\n",
        "for index, i in enumerate(list_of_vectors_in_many_histograms):\n",
        "  for index, j in enumerate(i):\n",
        "    list_of_vectors_in_one_list.append(j)\n",
        "\n",
        "from sklearn.impute import KNNImputer\n",
        "imputer = KNNImputer(n_neighbors=5)\n",
        "KNN_1 = imputer.fit_transform(list_of_vectors_in_one_list)\n",
        "\n",
        "cols = X_all.columns\n",
        "e = pd.DataFrame(KNN_1)\n",
        "e1 = pd.DataFrame(e.iloc[0:60000])\n",
        "e1= e1.reset_index(drop=True)\n",
        "e2 = pd.DataFrame(e.iloc[60000:120000])\n",
        "e2 = e2.reset_index(drop=True)\n",
        "e3 = pd.DataFrame(e.iloc[120000:180000])\n",
        "e3 = e3.reset_index(drop=True)\n",
        "e4 = pd.DataFrame(e.iloc[180000:240000])\n",
        "e4 = e4.reset_index(drop=True)\n",
        "e5 = pd.DataFrame(e.iloc[240000:300000])\n",
        "e5 = e5.reset_index(drop=True)\n",
        "e6 = pd.DataFrame(e.iloc[300000:360000])\n",
        "e6 = e6.reset_index(drop=True)\n",
        "e7 = pd.DataFrame(e.iloc[360000:420000])\n",
        "e7 = e7.reset_index(drop=True)\n",
        "\n",
        "knn_onen = pd.concat([e1,e2, e3, e4, e5, e6, e7], axis=1, sort=False)\n",
        "knn_onen.columns = [np.arange(0,knn_onen.shape[1])]\n",
        "knn_onen.columns = ['ag_000', 'ag_001', 'ag_002', 'ag_003', 'ag_004', 'ag_005', 'ag_006',\n",
        "       'ag_007', 'ag_008', 'ag_009', 'ay_000', 'ay_001', 'ay_002', 'ay_003',\n",
        "       'ay_004', 'ay_005', 'ay_006', 'ay_007', 'ay_008', 'ay_009', 'az_000',\n",
        "       'az_001', 'az_002', 'az_003', 'az_004', 'az_005', 'az_006', 'az_007',\n",
        "       'az_008', 'az_009', 'ba_000', 'ba_001', 'ba_002', 'ba_003', 'ba_004',\n",
        "       'ba_005', 'ba_006', 'ba_007', 'ba_008', 'ba_009', 'cn_000', 'cn_001',\n",
        "       'cn_002', 'cn_003', 'cn_004', 'cn_005', 'cn_006', 'cn_007', 'cn_008',\n",
        "       'cn_009', 'cs_000', 'cs_001', 'cs_002', 'cs_003', 'cs_004', 'cs_005',\n",
        "       'cs_006', 'cs_007', 'cs_008', 'cs_009', 'ee_000', 'ee_001', 'ee_002',\n",
        "       'ee_003', 'ee_004', 'ee_005', 'ee_006', 'ee_007', 'ee_008', 'ee_009']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7KIWChBGZAy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#THIS IS THE NORMALIZATION CELL for KNN_1.0\n",
        "#CREATE A LIST OF ALL HISTOGRAMS\n",
        "knn1_df = knn_onen\n",
        "cols = knn_onen.columns\n",
        "knn1list_hist = list()\n",
        "knn1temporary_list = list()\n",
        "for i, j in enumerate(cols[:-1]):\n",
        "\n",
        "  first_column = j\n",
        "  next_column = cols[i+1]\n",
        "  if  i == (len(cols)-2):\n",
        "    if first_column[0:2] == next_column[0:2]:\n",
        "      knn1temporary_list.append(knn1_df[first_column])\n",
        "      knn1temporary_list.append(knn1_df[next_column])\n",
        "      knn1list_hist.append(knn1temporary_list) \n",
        "    \n",
        "    else:\n",
        "      knn1temporary_list.append(knn1_df[first_column])\n",
        "      knn1list_hist.append(knn1temporary_list) \n",
        "      #throwing the old temporary away and create a new empty \"temporary list\"\n",
        "      knn1temporary_list = list()\n",
        "      knn1temporary_list.append(knn1_df[next_column])\n",
        "      knn1list_hist.append(knn1temporary_list) \n",
        "\n",
        "  elif first_column[0:2] == next_column[0:2]:\n",
        "    knn1temporary_list.append(knn1_df[first_column])\n",
        "\n",
        "  else: \n",
        "    #add the last column to the temporary list\n",
        "    knn1temporary_list.append(knn1_df[first_column])\n",
        "    knn1list_hist.append(knn1temporary_list) \n",
        "    #throwing the old temporary away and create a new empty \"temporary list\"\n",
        "    knn1temporary_list = list()\n",
        "\n",
        "\n",
        "#CREATE NEW LIST AND REPLACE THE ITEMS WITH THEIR WEIGHTS\n",
        "knn1list_hist2 = list()\n",
        "\n",
        "for histogram in knn1list_hist:\n",
        "  sum = 0\n",
        "  for item in histogram:\n",
        "    sum += item\n",
        "  for item in histogram:\n",
        "    j=item\n",
        "    for index, itemsItem in enumerate(item):\n",
        "      if sum[index]==0:\n",
        "        j[index] = itemsItem\n",
        "      else:\n",
        "        j[index] = itemsItem/sum[index]\n",
        "  \n",
        "    knn1list_hist2.append(j)\n",
        "\n",
        "#TRANSPOSE THE LIST TO A DATAFRAME ONCE AGAIN\n",
        "knn_one = pd.DataFrame(np.transpose(knn1list_hist2),columns=cols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDGPAnAzxbV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#KNN_2.0\n",
        "\n",
        "df1 = X_all.transpose()\n",
        "\n",
        "temporary_list= list()\n",
        "final_hist_list= list()\n",
        "counter=0\n",
        "for i in range(len(df1.columns)):\n",
        "    counter=0\n",
        "    temp=cols[0][:2]\n",
        "    for j in cols:\n",
        "        if temp!=j[:2]:\n",
        "            counter=counter+1\n",
        "            final_hist_list.append(temporary_list)\n",
        "            temporary_list= list()\n",
        "            temp = j[:2]\n",
        "        temporary_list.append(df1[i][j])\n",
        "    final_hist_list.append(temporary_list)\n",
        "    temporary_list=list()\n",
        "    counter=counter+1\n",
        "\n",
        "i=0\n",
        "\n",
        "last_hist_list=list()\n",
        "for i in range(counter):\n",
        "    last_hist_list.append([])\n",
        "i=0    \n",
        "while i < len(final_hist_list):\n",
        "    for j in range(counter):\n",
        "        last_hist_list[j].append(final_hist_list[i])\n",
        "        i=i+1 \n",
        "        \n",
        "from sklearn.impute import KNNImputer\n",
        "imputer = KNNImputer(n_neighbors=5)\n",
        "for i in range(counter):\n",
        "    last_hist_list[i] = imputer.fit_transform(last_hist_list[i])\n",
        "\n",
        "u= {}\n",
        "cnty=0\n",
        "for i in last_hist_list:\n",
        "    i.transpose()\n",
        "    i= np.array(i).transpose()\n",
        "    for j in i:\n",
        "        u[cols[cnty]]=j\n",
        "        cnty=cnty+1    \n",
        "knn_twon = pd.DataFrame(u)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_BzRfBYHFB9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#THIS IS THE NORMALIZATION CELL for KNN_2.0\n",
        "#CREATE A LIST OF ALL HISTOGRAMS\n",
        "knn2_df = knn_twon\n",
        "cols = knn_twon.columns\n",
        "knn2list_hist = list()\n",
        "knn2temporary_list = list()\n",
        "for i, j in enumerate(cols[:-1]):\n",
        "\n",
        "  first_column = j\n",
        "  next_column = cols[i+1]\n",
        "  if  i == (len(cols)-2):\n",
        "    if first_column[0:2] == next_column[0:2]:\n",
        "      knn2temporary_list.append(knn2_df[first_column])\n",
        "      knn2temporary_list.append(knn2_df[next_column])\n",
        "      knn2list_hist.append(knn2temporary_list) \n",
        "    \n",
        "    else:\n",
        "      knn2temporary_list.append(knn2_df[first_column])\n",
        "      knn2list_hist.append(knn2temporary_list) \n",
        "      #throwing the old temporary away and create a new empty \"temporary list\"\n",
        "      knn2temporary_list = list()\n",
        "      knn2temporary_list.append(knn2_df[next_column])\n",
        "      knn2list_hist.append(knn2temporary_list) \n",
        "\n",
        "  elif first_column[0:2] == next_column[0:2]:\n",
        "    knn2temporary_list.append(knn2_df[first_column])\n",
        "\n",
        "  else: \n",
        "    #add the last column to the temporary list\n",
        "    knn2temporary_list.append(knn2_df[first_column])\n",
        "    knn2list_hist.append(knn2temporary_list) \n",
        "    #throwing the old temporary away and create a new empty \"temporary list\"\n",
        "    knn2temporary_list = list()\n",
        "\n",
        "\n",
        "#CREATE NEW LIST AND REPLACE THE ITEMS WITH THEIR WEIGHTS\n",
        "knn2list_hist2 = list()\n",
        "\n",
        "for histogram in knn2list_hist:\n",
        "  sum = 0\n",
        "  for item in histogram:\n",
        "    sum += item\n",
        "  for item in histogram:\n",
        "    j=item\n",
        "    for index, itemsItem in enumerate(item):\n",
        "      if sum[index]==0:\n",
        "        j[index] = itemsItem\n",
        "      else:\n",
        "        j[index] = itemsItem/sum[index]\n",
        "  \n",
        "    knn2list_hist2.append(j)\n",
        "\n",
        "#TRANSPOSE THE LIST TO A DATAFRAME ONCE AGAIN\n",
        "knn_two = pd.DataFrame(np.transpose(knn2list_hist2),columns=cols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0svvpavuHcIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SCALE KNN_1.0 and 2.0 as well.\n",
        "\n",
        "knn_one_scaled = scaler.fit_transform(knn_onen)\n",
        "knn_two_scaled = scaler.fit_transform(knn_twon)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFqiY35eg8gC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This is done to enable XGBoost to work\n",
        "knn = knnDF.values\n",
        "mean = meanDF.values\n",
        "median = medianDF.values\n",
        "knn1 = knn_one.values\n",
        "knn2 = knn_two.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6aEys1exG_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#All with 'v' are used only when applying XGBoost, all with 'sc' indicates the scaled dataframes and the rest are applied with hist_norm\n",
        "\n",
        "Xknn_train, Xknn_test, yknn_train, yknn_test = train_test_split (knnDF, y_all, \n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 10)\n",
        "\n",
        "Xknnv_train, Xknnv_test, yknnv_train, yknnv_test = train_test_split (knn, y_all, \n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 10)\n",
        "\n",
        "Xknnsc_train, Xknnsc_test, yknnsc_train, yknnsc_test = train_test_split (knnDF_scaled, y_all, \n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 10)\n",
        "\n",
        "Xmean_train, Xmean_test, ymean_train, ymean_test = train_test_split (meanDF, y_all, \n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 10)\n",
        "\n",
        "Xmeanv_train, Xmeanv_test, ymeanv_train, ymeanv_test = train_test_split (mean, y_all, \n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 10)\n",
        "\n",
        "Xmeansc_train, Xmeansc_test, ymeansc_train, ymeansc_test = train_test_split (meanDF_scaled, y_all, \n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 10)\n",
        "\n",
        "Xmedian_train, Xmedian_test, ymedian_train, ymedian_test = train_test_split (medianDF, y_all, \n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 10)\n",
        "\n",
        "Xmedianv_train, Xmedianv_test, ymedianv_train, ymedianv_test = train_test_split (median, y_all, \n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 10)\n",
        "\n",
        "Xmediansc_train, Xmediansc_test, ymediansc_train, ymediansc_test = train_test_split (medianDF_scaled, y_all, \n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 10)\n",
        "\n",
        "Xknn1_train, Xknn1_test, yknn1_train, yknn1_test = train_test_split (knn_one, y_all, \n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 10)\n",
        "\n",
        "Xknn1sc_train, Xknn1sc_test, yknn1sc_train, yknn1sc_test = train_test_split (knn_one_scaled, y_all, \n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 10)\n",
        "\n",
        "Xknn1v_train, Xknn1v_test, yknn1v_train, yknn1v_test = train_test_split (knn1, y_all, \n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 10)\n",
        "\n",
        "Xknn2_train, Xknn2_test, yknn2_train, yknn2_test = train_test_split (knn_two, y_all, \n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 10)\n",
        "\n",
        "Xknn2v_train, Xknn2v_test, yknn2v_train, yknn2v_test = train_test_split (knn2, y_all, \n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 10)\n",
        "\n",
        "Xknn2sc_train, Xknn2sc_test, yknn2sc_train, yknn2sc_test = train_test_split (knn_two_scaled, y_all, \n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPoEy2Jf4qCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "# Initialize the models\n",
        "clf_A = LogisticRegression(solver='sag', random_state = 42, max_iter=1000000)\n",
        "clf_B = SVC(probability=True, random_state = 912, kernel='rbf')\n",
        "clf_C = xgb.XGBClassifier()\n",
        "clf_D = RandomForestClassifier(n_estimators = 128, max_depth=50)\n",
        "\n",
        "#hist_norm data\n",
        "\n",
        "clf_A.fit(Xknn_train, yknn_train)\n",
        "clf_B.fit(Xknn_train, yknn_train)\n",
        "clf_C.fit(Xknnv_train, yknnv_train)\n",
        "clf_D.fit(Xknn_train, yknn_train)\n",
        "\n",
        "clf_A.fit(Xmean_train, ymean_train)\n",
        "clf_B.fit(Xmean_train, ymean_train)\n",
        "clf_C.fit(Xmeanv_train, ymeanv_train)\n",
        "clf_D.fit(Xmean_train, ymean_train)\n",
        "\n",
        "clf_A.fit(Xmedian_train, ymedian_train)\n",
        "clf_B.fit(Xmedian_train, ymedian_train)\n",
        "clf_C.fit(Xmedianv_train, ymedianv_train)\n",
        "clf_D.fit(Xmedian_train, ymedian_train)\n",
        "\n",
        "clf_A.fit(Xknn1_train, yknn1_train)\n",
        "clf_B.fit(Xknn1_train, yknn1_train)\n",
        "clf_C.fit(Xknn1v_train, yknn1v_train)\n",
        "clf_D.fit(Xknn1_train, yknn1_train)\n",
        "\n",
        "clf_A.fit(Xknn2_train, yknn2_train)\n",
        "clf_B.fit(Xknn2_train, yknn2_train)\n",
        "clf_C.fit(Xknn2v_train, yknn2v_train)\n",
        "clf_D.fit(Xknn2_train, yknn2_train)\n",
        "\n",
        "# scaled data\n",
        "clf_A.fit(Xknnsc_train, yknnsc_train)\n",
        "clf_B.fit(Xknnsc_train, yknnsc_train)\n",
        "clf_C.fit(Xknnsc_train, yknnsc_train)\n",
        "clf_D.fit(Xknnsc_train, yknnsc_train)\n",
        "\n",
        "clf_A.fit(Xmeansc_train, ymeansc_train)\n",
        "clf_B.fit(Xmeansc_train, ymeansc_train)\n",
        "clf_C.fit(Xmeansc_train, ymeansc_train)\n",
        "clf_D.fit(Xmeansc_train, ymeansc_train)\n",
        "\n",
        "clf_A.fit(Xmediansc_train, ymediansc_train)\n",
        "clf_B.fit(Xmediansc_train, ymediansc_train)\n",
        "clf_C.fit(Xmediansc_train, ymediansc_train)\n",
        "clf_D.fit(Xmediansc_train, ymediansc_train)\n",
        "\n",
        "clf_A.fit(Xknn1sc_train, yknn1sc_train)\n",
        "clf_B.fit(Xknn1sc_train, yknn1sc_train)\n",
        "clf_C.fit(Xknn1sc_train, yknn1sc_train)\n",
        "clf_D.fit(Xknn1sc_train, yknn1sc_train)\n",
        "\n",
        "clf_A.fit(Xknn2sc_train, yknn2sc_train)\n",
        "clf_B.fit(Xknn2sc_train, yknn2sc_train)\n",
        "clf_C.fit(Xknn2sc_train, yknn2sc_train)\n",
        "clf_D.fit(Xknn2sc_train, yknn2sc_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28AscCsg5n_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
        "\n",
        "\n",
        "#********KNN_histnorm******************\n",
        "\n",
        "#AUC\n",
        "knn_lr_probs = clf_A.predict_proba(Xknn_test)\n",
        "knn_svm_probs = clf_B.predict_proba(Xknn_test)\n",
        "knn_xgb_probs = clf_C.predict_proba(Xknnv_test)\n",
        "knn_rf_probs = clf_D.predict_proba(Xknn_test)\n",
        "\n",
        "knn_lr_probs = knn_lr_probs[:, 1]\n",
        "knn_svm_probs = knn_svm_probs[:, 1]\n",
        "knn_xgb_probs = knn_xgb_probs[:, 1]\n",
        "knn_rf_probs = knn_rf_probs[:, 1]\n",
        "# calculate scores\n",
        "knn_lr_auc = roc_auc_score(yknn_test, knn_lr_probs)\n",
        "knn_svm_auc = roc_auc_score(yknn_test, knn_svm_probs)\n",
        "knn_xgb_auc = roc_auc_score(yknnv_test, knn_xgb_probs)\n",
        "knn_rf_auc = roc_auc_score(yknn_test, knn_rf_probs)\n",
        "\n",
        "# OTHER METRICS for standard KNN\n",
        "knn_lr_pred = clf_A.predict(Xknn_test)\n",
        "knn_s_pred = clf_B.predict(Xknn_test)\n",
        "knn_x_pred = clf_C.predict(Xknnv_test)\n",
        "knn_rf_pred = clf_D.predict(Xknn_test)\n",
        "\n",
        "\n",
        "#********KNN_scaled******************\n",
        "\n",
        "#AUC\n",
        "knnsc_lr_probs = clf_A.predict_proba(Xknnsc_test)\n",
        "knnsc_svm_probs = clf_B.predict_proba(Xknnsc_test)\n",
        "knnsc_xgb_probs = clf_C.predict_proba(Xknnsc_test)\n",
        "knnsc_rf_probs = clf_D.predict_proba(Xknnsc_test)\n",
        "\n",
        "knnsc_lr_probs = knnsc_lr_probs[:, 1]\n",
        "knnsc_svm_probs = knnsc_svm_probs[:, 1]\n",
        "knnsc_xgb_probs = knnsc_xgb_probs[:, 1]\n",
        "knnsc_rf_probs = knnsc_rf_probs[:, 1]\n",
        "# calculate scores\n",
        "knnsc_lr_auc = roc_auc_score(yknnsc_test, knnsc_lr_probs)\n",
        "knnsc_svm_auc = roc_auc_score(yknnsc_test, knnsc_svm_probs)\n",
        "knnsc_xgb_auc = roc_auc_score(yknnsc_test, knnsc_xgb_probs)\n",
        "knnsc_rf_auc = roc_auc_score(yknnsc_test, knnsc_rf_probs)\n",
        "\n",
        "# OTHER METRICS for standard KNN\n",
        "knnsc_lr_pred = clf_A.predict(Xknnsc_test)\n",
        "knnsc_s_pred = clf_B.predict(Xknnsc_test)\n",
        "knnsc_x_pred = clf_C.predict(Xknnsc_test)\n",
        "knnsc_rf_pred = clf_D.predict(Xknnsc_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#********MEAN_histnorm******************\n",
        "\n",
        "mean_lr_probs = clf_A.predict_proba(Xmean_test)\n",
        "mean_svm_probs = clf_B.predict_proba(Xmean_test)\n",
        "mean_xgb_probs = clf_C.predict_proba(Xmeanv_test)\n",
        "mean_rf_probs = clf_D.predict_proba(Xmean_test)\n",
        "\n",
        "mean_lr_probs = mean_lr_probs[:, 1]\n",
        "mean_svm_probs = mean_svm_probs[:, 1]\n",
        "mean_xgb_probs = mean_xgb_probs[:, 1]\n",
        "mean_rf_probs = mean_rf_probs[:, 1]\n",
        "# calculate scores\n",
        "mean_lr_auc = roc_auc_score(ymean_test, mean_lr_probs)\n",
        "mean_svm_auc = roc_auc_score(ymean_test, mean_svm_probs)\n",
        "mean_xgb_auc = roc_auc_score(ymeanv_test, mean_xgb_probs)\n",
        "mean_rf_auc = roc_auc_score(ymean_test, mean_rf_probs)\n",
        "\n",
        "# OTHER METRICS for standard MEAN\n",
        "mean_lr_pred = clf_A.predict(Xmean_test)\n",
        "mean_s_pred = clf_B.predict(Xmean_test)\n",
        "mean_x_pred = clf_C.predict(Xmeanv_test)\n",
        "mean_rf_pred = clf_D.predict(Xmean_test)\n",
        "\n",
        "\n",
        "#********MEAN_scaled******************\n",
        "\n",
        "meansc_lr_probs = clf_A.predict_proba(Xmeansc_test)\n",
        "meansc_svm_probs = clf_B.predict_proba(Xmeansc_test)\n",
        "meansc_xgb_probs = clf_C.predict_proba(Xmeansc_test)\n",
        "meansc_rf_probs = clf_D.predict_proba(Xmeansc_test)\n",
        "\n",
        "meansc_lr_probs = meansc_lr_probs[:, 1]\n",
        "meansc_svm_probs = meansc_svm_probs[:, 1]\n",
        "meansc_xgb_probs = meansc_xgb_probs[:, 1]\n",
        "meansc_rf_probs = meansc_rf_probs[:, 1]\n",
        "# calculate scores\n",
        "meansc_lr_auc = roc_auc_score(ymeansc_test, meansc_lr_probs)\n",
        "meansc_svm_auc = roc_auc_score(ymeansc_test, meansc_svm_probs)\n",
        "meansc_xgb_auc = roc_auc_score(ymeansc_test, meansc_xgb_probs)\n",
        "meansc_rf_auc = roc_auc_score(ymeansc_test, meansc_rf_probs)\n",
        "\n",
        "# OTHER METRICS for standard MEAN\n",
        "meansc_lr_pred = clf_A.predict(Xmeansc_test)\n",
        "meansc_s_pred = clf_B.predict(Xmeansc_test)\n",
        "meansc_x_pred = clf_C.predict(Xmeansc_test)\n",
        "meansc_rf_pred = clf_D.predict(Xmeansc_test)\n",
        "\n",
        "\n",
        "\n",
        "#********MEDIAN_histnorm******************\n",
        "\n",
        "median_lr_probs = clf_A.predict_proba(Xmedian_test)\n",
        "median_svm_probs = clf_B.predict_proba(Xmedian_test)\n",
        "median_xgb_probs = clf_C.predict_proba(Xmedianv_test)\n",
        "median_rf_probs = clf_D.predict_proba(Xmedian_test)\n",
        "\n",
        "median_lr_probs = median_lr_probs[:, 1]\n",
        "median_svm_probs = median_svm_probs[:, 1]\n",
        "median_xgb_probs = median_xgb_probs[:, 1]\n",
        "median_rf_probs = median_rf_probs[:, 1]\n",
        "# calculate scores\n",
        "median_lr_auc = roc_auc_score(ymedian_test, median_lr_probs)\n",
        "median_svm_auc = roc_auc_score(ymedian_test, median_svm_probs)\n",
        "median_xgb_auc = roc_auc_score(ymedianv_test, median_xgb_probs)\n",
        "median_rf_auc = roc_auc_score(ymedian_test, median_rf_probs)\n",
        "\n",
        "# OTHER METRICS for standard MEDIAN\n",
        "median_lr_pred = clf_A.predict(Xmedian_test)\n",
        "median_s_pred = clf_B.predict(Xmedian_test)\n",
        "median_x_pred = clf_C.predict(Xmedianv_test)\n",
        "median_rf_pred = clf_D.predict(Xmedian_test)\n",
        "\n",
        "\n",
        "#********MEDIAN_scaled******************\n",
        "\n",
        "mediansc_lr_probs = clf_A.predict_proba(Xmediansc_test)\n",
        "mediansc_svm_probs = clf_B.predict_proba(Xmediansc_test)\n",
        "mediansc_xgb_probs = clf_C.predict_proba(Xmediansc_test)\n",
        "mediansc_rf_probs = clf_D.predict_proba(Xmediansc_test)\n",
        "\n",
        "mediansc_lr_probs = mediansc_lr_probs[:, 1]\n",
        "mediansc_svm_probs = mediansc_svm_probs[:, 1]\n",
        "mediansc_xgb_probs = mediansc_xgb_probs[:, 1]\n",
        "mediansc_rf_probs = mediansc_rf_probs[:, 1]\n",
        "# calculate scores\n",
        "mediansc_lr_auc = roc_auc_score(ymediansc_test, mediansc_lr_probs)\n",
        "mediansc_svm_auc = roc_auc_score(ymediansc_test, mediansc_svm_probs)\n",
        "mediansc_xgb_auc = roc_auc_score(ymediansc_test, mediansc_xgb_probs)\n",
        "mediansc_rf_auc = roc_auc_score(ymediansc_test, mediansc_rf_probs)\n",
        "\n",
        "# OTHER METRICS for standard MEDIAN\n",
        "mediansc_lr_pred = clf_A.predict(Xmediansc_test)\n",
        "mediansc_s_pred = clf_B.predict(Xmediansc_test)\n",
        "mediansc_x_pred = clf_C.predict(Xmediansc_test)\n",
        "mediansc_rf_pred = clf_D.predict(Xmediansc_test)\n",
        "\n",
        "\n",
        "\n",
        "#********KNN_1.0_histnorm******************\n",
        "\n",
        "#AUC\n",
        "knn1_lr_probs = clf_A.predict_proba(Xknn1_test)\n",
        "knn1_svm_probs = clf_B.predict_proba(Xknn1_test)\n",
        "knn1_xgb_probs = clf_C.predict_proba(Xknn1v_test)\n",
        "knn1_rf_probs = clf_D.predict_proba(Xknn1_test)\n",
        "\n",
        "knn1_lr_probs = knn1_lr_probs[:, 1]\n",
        "knn1_svm_probs = knn1_svm_probs[:, 1]\n",
        "knn1_xgb_probs = knn1_xgb_probs[:, 1]\n",
        "knn1_rf_probs = knn1_rf_probs[:, 1]\n",
        "# calculate scores\n",
        "knn1_lr_auc = roc_auc_score(yknn1_test, knn1_lr_probs)\n",
        "knn1_svm_auc = roc_auc_score(yknn1_test, knn1_svm_probs)\n",
        "knn1_xgb_auc = roc_auc_score(yknn1v_test, knn1_xgb_probs)\n",
        "knn1_rf_auc = roc_auc_score(yknn1_test, knn1_rf_probs)\n",
        "\n",
        "# OTHER METRICS for standard KNN_1.0\n",
        "knn1_lr_pred = clf_A.predict(Xknn1_test)\n",
        "knn1_s_pred = clf_B.predict(Xknn1_test)\n",
        "knn1_x_pred = clf_C.predict(Xknn1v_test)\n",
        "knn1_rf_pred = clf_D.predict(Xknn1_test)\n",
        "\n",
        "\n",
        "#********KNN_1.0_scaled******************\n",
        "\n",
        "#AUC\n",
        "knn1sc_lr_probs = clf_A.predict_proba(Xknn1sc_test)\n",
        "knn1sc_svm_probs = clf_B.predict_proba(Xknn1sc_test)\n",
        "knn1sc_xgb_probs = clf_C.predict_proba(Xknn1sc_test)\n",
        "knn1sc_rf_probs = clf_D.predict_proba(Xknn1sc_test)\n",
        "\n",
        "knn1sc_lr_probs = knn1sc_lr_probs[:, 1]\n",
        "knn1sc_svm_probs = knn1sc_svm_probs[:, 1]\n",
        "knn1sc_xgb_probs = knn1sc_xgb_probs[:, 1]\n",
        "knn1sc_rf_probs = knn1sc_rf_probs[:, 1]\n",
        "# calculate scores\n",
        "knn1sc_lr_auc = roc_auc_score(yknn1sc_test, knn1sc_lr_probs)\n",
        "knn1sc_svm_auc = roc_auc_score(yknn1sc_test, knn1sc_svm_probs)\n",
        "knn1sc_xgb_auc = roc_auc_score(yknn1sc_test, knn1sc_xgb_probs)\n",
        "knn1sc_rf_auc = roc_auc_score(yknn1sc_test, knn1sc_rf_probs)\n",
        "\n",
        "# OTHER METRICS for standard KNN_1.0\n",
        "knn1sc_lr_pred = clf_A.predict(Xknn1sc_test)\n",
        "knn1sc_s_pred = clf_B.predict(Xknn1sc_test)\n",
        "knn1sc_x_pred = clf_C.predict(Xknn1sc_test)\n",
        "knn1sc_rf_pred = clf_D.predict(Xknn1sc_test)\n",
        "\n",
        "\n",
        "#********KNN_2.0_histnorm******************\n",
        "\n",
        "#AUC\n",
        "knn2_lr_probs = clf_A.predict_proba(Xknn2_test)\n",
        "knn2_svm_probs = clf_B.predict_proba(Xknn2_test)\n",
        "knn2_xgb_probs = clf_C.predict_proba(Xknn2v_test)\n",
        "knn2_rf_probs = clf_D.predict_proba(Xknn2_test)\n",
        "\n",
        "knn2_lr_probs = knn2_lr_probs[:, 1]\n",
        "knn2_svm_probs = knn2_svm_probs[:, 1]\n",
        "knn2_xgb_probs = knn2_xgb_probs[:, 1]\n",
        "knn2_rf_probs = knn2_rf_probs[:, 1]\n",
        "# calculate scores\n",
        "knn2_lr_auc = roc_auc_score(yknn2_test, knn2_lr_probs)\n",
        "knn2_svm_auc = roc_auc_score(yknn2_test, knn2_svm_probs)\n",
        "knn2_xgb_auc = roc_auc_score(yknn2v_test, knn2_xgb_probs)\n",
        "knn2_rf_auc = roc_auc_score(yknn2_test, knn2_rf_probs)\n",
        "\n",
        "# OTHER METRICS for standard KNN\n",
        "knn2_lr_pred = clf_A.predict(Xknn2_test)\n",
        "knn2_s_pred = clf_B.predict(Xknn2_test)\n",
        "knn2_x_pred = clf_C.predict(Xknn2v_test)\n",
        "knn2_rf_pred = clf_D.predict(Xknn2_test)\n",
        "\n",
        "\n",
        "#********KNN_2.0_scaled******************\n",
        "\n",
        "#AUC\n",
        "knn2sc_lr_probs = clf_A.predict_proba(Xknn2sc_test)\n",
        "knn2sc_svm_probs = clf_B.predict_proba(Xknn2sc_test)\n",
        "knn2sc_xgb_probs = clf_C.predict_proba(Xknn2sc_test)\n",
        "knn2sc_rf_probs = clf_D.predict_proba(Xknn2sc_test)\n",
        "\n",
        "knn2sc_lr_probs = knn2sc_lr_probs[:, 1]\n",
        "knn2sc_svm_probs = knn2sc_svm_probs[:, 1]\n",
        "knn2sc_xgb_probs = knn2sc_xgb_probs[:, 1]\n",
        "knn2sc_rf_probs = knn2sc_rf_probs[:, 1]\n",
        "# calculate scores\n",
        "knn2sc_lr_auc = roc_auc_score(yknn2sc_test, knn2sc_lr_probs)\n",
        "knn2sc_svm_auc = roc_auc_score(yknn2sc_test, knn2sc_svm_probs)\n",
        "knn2sc_xgb_auc = roc_auc_score(yknn2sc_test, knn2sc_xgb_probs)\n",
        "knn2sc_rf_auc = roc_auc_score(yknn2sc_test, knn2sc_rf_probs)\n",
        "\n",
        "# OTHER METRICS for standard KNN\n",
        "knn2sc_lr_pred = clf_A.predict(Xknn2sc_test)\n",
        "knn2sc_s_pred = clf_B.predict(Xknn2sc_test)\n",
        "knn2sc_x_pred = clf_C.predict(Xknn2sc_test)\n",
        "knn2sc_rf_pred = clf_D.predict(Xknn2sc_test)\n",
        "\n",
        "#Summarize the scores\n",
        "print ('KNN with hist_norm')\n",
        "print ('LOGISTIC REGRESSION')\n",
        "print('AUC score: %.3f' % (knn_lr_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn_test, knn_lr_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn_test, knn_lr_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn_test, knn_lr_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn_test, knn_lr_pred)))\n",
        "print('')\n",
        "print ('SVM')\n",
        "print('AUC score: %.3f' % (knn_svm_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn_test, knn_s_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn_test, knn_s_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn_test, knn_s_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn_test, knn_s_pred)))\n",
        "print('')\n",
        "print ('XGBOOST')\n",
        "print('AUC score: %.3f' % (knn_xgb_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknnv_test, knn_x_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknnv_test, knn_x_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknnv_test, knn_x_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknnv_test, knn_x_pred)))\n",
        "print('')\n",
        "print ('RANDOM FOREST')\n",
        "print('AUC score: %.3f' % (knn_rf_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn_test, knn_rf_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn_test, knn_rf_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn_test, knn_rf_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn_test, knn_rf_pred)))\n",
        "print('')\n",
        "print('')\n",
        "print('')\n",
        "print ('MEAN with hist_norm')\n",
        "print ('LOGISTIC REGRESSION')\n",
        "print('AUC score: %.3f' % (mean_lr_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymean_test, mean_lr_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymean_test, mean_lr_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymean_test, mean_lr_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymean_test, mean_lr_pred)))\n",
        "print('')\n",
        "print ('SVM')\n",
        "print('AUC score: %.3f' % (mean_svm_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymean_test, mean_s_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymean_test, mean_s_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymean_test, mean_s_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymean_test, mean_s_pred)))\n",
        "print('')\n",
        "print ('XGBOOST')\n",
        "print('AUC score: %.3f' % (mean_xgb_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymeanv_test, mean_x_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymeanv_test, mean_x_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymeanv_test, mean_x_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymeanv_test, mean_x_pred)))\n",
        "print('')\n",
        "print ('RANDOM FOREST')\n",
        "print('AUC score: %.3f' % (mean_rf_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymean_test, mean_rf_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymean_test, mean_rf_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymean_test, mean_rf_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymean_test, mean_rf_pred)))\n",
        "print('')\n",
        "print('')\n",
        "print('')\n",
        "print ('MEDIAN with hist_norm')\n",
        "print ('LOGISTIC REGRESSION')\n",
        "print('AUC score: %.3f' % (median_lr_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymedian_test, median_lr_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymedian_test, median_lr_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymedian_test, median_lr_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymedian_test, median_lr_pred)))\n",
        "print('')\n",
        "print ('SVM')\n",
        "print('AUC score: %.3f' % (median_svm_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymedian_test, median_s_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymedian_test, median_s_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymedian_test, median_s_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymedian_test, median_s_pred)))\n",
        "print('')\n",
        "print ('XGBOOST')\n",
        "print('AUC score: %.3f' % (median_xgb_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymedianv_test, median_x_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymedianv_test, median_x_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymedianv_test, median_x_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymedian_test, median_x_pred)))\n",
        "print('')\n",
        "print ('RANDOM FOREST')\n",
        "print('AUC score: %.3f' % (median_rf_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymedian_test, median_rf_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymedian_test, median_rf_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymedian_test, median_rf_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymedian_test, median_rf_pred)))\n",
        "print('')\n",
        "print('')\n",
        "print('')\n",
        "print ('KNN_1.0 with hist_norm')\n",
        "print ('LOGISTIC REGRESSION')\n",
        "print('AUC score: %.3f' % (knn1_lr_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn1_test, knn1_lr_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn1_test, knn1_lr_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn1_test, knn1_lr_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn1_test, knn1_lr_pred)))\n",
        "print('')\n",
        "print ('SVM')\n",
        "print('AUC score: %.3f' % (knn1_svm_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn1_test, knn1_s_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn1_test, knn1_s_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn1_test, knn1_s_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn1_test, knn1_s_pred)))\n",
        "print('')\n",
        "print ('XGBOOST')\n",
        "print('AUC score: %.3f' % (knn1_xgb_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn1v_test, knn1_x_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn1v_test, knn1_x_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn1v_test, knn1_x_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn1v_test, knn1_x_pred)))\n",
        "print('')\n",
        "print ('RANDOM FOREST')\n",
        "print('AUC score: %.3f' % (knn1_rf_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn1_test, knn1_rf_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn1_test, knn1_rf_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn1_test, knn1_rf_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn1_test, knn1_rf_pred)))\n",
        "print('')\n",
        "print('')\n",
        "print('')\n",
        "print ('KNN_2.0 with hist_norm')\n",
        "print ('LOGISTIC REGRESSION')\n",
        "print('AUC score: %.3f' % (knn2_lr_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn2_test, knn2_lr_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn2_test, knn2_lr_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn2_test, knn2_lr_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn2_test, knn2_lr_pred)))\n",
        "print('')\n",
        "print ('SVM')\n",
        "print('AUC score: %.3f' % (knn2_svm_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn2_test, knn2_s_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn2_test, knn2_s_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn2_test, knn2_s_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn2_test, knn2_s_pred)))\n",
        "print('')\n",
        "print ('XGBOOST')\n",
        "print('AUC score: %.3f' % (knn2_xgb_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn2v_test, knn2_x_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn2v_test, knn2_x_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn2v_test, knn2_x_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn2v_test, knn2_x_pred)))\n",
        "print('')\n",
        "print ('RANDOM FOREST')\n",
        "print('AUC score: %.3f' % (knn2_rf_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn2_test, knn2_rf_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn2_test, knn2_rf_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn2_test, knn2_rf_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn2_test, knn2_rf_pred)))\n",
        "print('')\n",
        "print('')\n",
        "print('')\n",
        "print ('KNN scaled')\n",
        "print ('LOGISTIC REGRESSION')\n",
        "print('AUC score: %.3f' % (knnsc_lr_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknnsc_test, knnsc_lr_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknnsc_test, knnsc_lr_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknnsc_test, knnsc_lr_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknnsc_test, knnsc_lr_pred)))\n",
        "print('')\n",
        "print ('SVM')\n",
        "print('AUC score: %.3f' % (knnsc_svm_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknnsc_test, knnsc_s_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknnsc_test, knnsc_s_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknnsc_test, knnsc_s_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknnsc_test, knnsc_s_pred)))\n",
        "print('')\n",
        "print ('XGBOOST')\n",
        "print('AUC score: %.3f' % (knnsc_xgb_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknnsc_test, knnsc_x_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknnsc_test, knnsc_x_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknnsc_test, knnsc_x_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknnsc_test, knnsc_x_pred)))\n",
        "print('')\n",
        "print ('RANDOM FOREST')\n",
        "print('AUC score: %.3f' % (knnsc_rf_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknnsc_test, knnsc_rf_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknnsc_test, knnsc_rf_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknnsc_test, knnsc_rf_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknnsc_test, knnsc_rf_pred)))\n",
        "print('')\n",
        "print('')\n",
        "print('')\n",
        "print ('MEAN scaled')\n",
        "print ('LOGISTIC REGRESSION')\n",
        "print('AUC score: %.3f' % (meansc_lr_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymeansc_test, meansc_lr_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymeansc_test, meansc_lr_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymeansc_test, meansc_lr_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymeansc_test, meansc_lr_pred)))\n",
        "print('')\n",
        "print ('SVM')\n",
        "print('AUC score: %.3f' % (meansc_svm_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymeansc_test, meansc_s_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymeansc_test, meansc_s_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymeansc_test, meansc_s_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymeansc_test, meansc_s_pred)))\n",
        "print('')\n",
        "print ('XGBOOST')\n",
        "print('AUC score: %.3f' % (meansc_xgb_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymeansc_test, meansc_x_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymeansc_test, meansc_x_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymeansc_test, meansc_x_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymeansc_test, meansc_x_pred)))\n",
        "print('')\n",
        "print ('RANDOM FOREST')\n",
        "print('AUC score: %.3f' % (meansc_rf_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymeansc_test, meansc_rf_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymeansc_test, meansc_rf_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymeansc_test, meansc_rf_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymeansc_test, meansc_rf_pred)))\n",
        "print('')\n",
        "print('')\n",
        "print('')\n",
        "print ('MEDIAN scaled')\n",
        "print ('LOGISTIC REGRESSION')\n",
        "print('AUC score: %.3f' % (mediansc_lr_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymediansc_test, mediansc_lr_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymediansc_test, mediansc_lr_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymediansc_test, mediansc_lr_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymediansc_test, mediansc_lr_pred)))\n",
        "print('')\n",
        "print ('SVM')\n",
        "print('AUC score: %.3f' % (mediansc_svm_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymediansc_test, mediansc_s_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymediansc_test, mediansc_s_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymediansc_test, mediansc_s_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymediansc_test, mediansc_s_pred)))\n",
        "print('')\n",
        "print ('XGBOOST')\n",
        "print('AUC score: %.3f' % (mediansc_xgb_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymediansc_test, mediansc_x_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymediansc_test, mediansc_x_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymediansc_test, mediansc_x_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymediansc_test, mediansc_x_pred)))\n",
        "print('')\n",
        "print ('RANDOM FOREST')\n",
        "print('AUC score: %.3f' % (mediansc_rf_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymediansc_test, mediansc_rf_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymediansc_test, mediansc_rf_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymediansc_test, mediansc_rf_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymediansc_test, mediansc_rf_pred)))\n",
        "print('')\n",
        "print('')\n",
        "print('')\n",
        "print ('KNN_1.0 scaled')\n",
        "print ('LOGISTIC REGRESSION')\n",
        "print('AUC score: %.3f' % (knn1sc_lr_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn1sc_test, knn1sc_lr_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn1sc_test, knn1sc_lr_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn1sc_test, knn1sc_lr_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn1sc_test, knn1sc_lr_pred)))\n",
        "print('')\n",
        "print ('SVM')\n",
        "print('AUC score: %.3f' % (knn1sc_svm_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn1sc_test, knn1sc_s_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn1sc_test, knn1sc_s_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn1sc_test, knn1sc_s_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn1sc_test, knn1sc_s_pred)))\n",
        "print('')\n",
        "print ('XGBOOST')\n",
        "print('AUC score: %.3f' % (knn1sc_xgb_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn1sc_test, knn1sc_x_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn1sc_test, knn1sc_x_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn1sc_test, knn1sc_x_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn1sc_test, knn1sc_x_pred)))\n",
        "print('')\n",
        "print ('RANDOM FOREST')\n",
        "print('AUC score: %.3f' % (knn1sc_rf_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn1sc_test, knn1sc_rf_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn1sc_test, knn1sc_rf_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn1sc_test, knn1sc_rf_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn1sc_test, knn1sc_rf_pred)))\n",
        "print('')\n",
        "print('')\n",
        "print('')\n",
        "print ('KNN_2.0 scaled')\n",
        "print ('LOGISTIC REGRESSION')\n",
        "print('AUC score: %.3f' % (knn2sc_lr_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn2sc_test, knn2sc_lr_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn2sc_test, knn2sc_lr_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn2sc_test, knn2sc_lr_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn2sc_test, knn2sc_lr_pred)))\n",
        "print('')\n",
        "print ('SVM')\n",
        "print('AUC score: %.3f' % (knn2sc_svm_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn2sc_test, knn2sc_s_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn2sc_test, knn2sc_s_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn2sc_test, knn2sc_s_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn2sc_test, knn2sc_s_pred)))\n",
        "print('')\n",
        "print ('XGBOOST')\n",
        "print('AUC score: %.3f' % (knn2sc_xgb_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn2sc_test, knn2sc_x_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn2sc_test, knn2sc_x_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn2sc_test, knn2sc_x_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn2sc_test, knn2sc_x_pred)))\n",
        "print('')\n",
        "print ('RANDOM FOREST')\n",
        "print('AUC score: %.3f' % (knn2sc_rf_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn2sc_test, knn2sc_rf_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn2sc_test, knn2sc_rf_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn2sc_test, knn2sc_rf_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn2sc_test, knn2sc_rf_pred)))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}