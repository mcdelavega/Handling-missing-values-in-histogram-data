{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "All_methods_aps_normalized.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOWX8wH/3vYPz1utlGlRanf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mcdelavega/Handling-missing-values-in-histogram-data/blob/master/All_methods_aps_normalized.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfa4KV4zu8Vg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "f72a9c50-6b4a-4627-df33-8349899a96c2"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns  \n",
        "import pandas.util.testing as tm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gacoelE_vFbA",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "f7591854-701c-4b1e-c61b-bb2c23abd575"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-df62f55a-b032-484a-9a48-fb962f8108d6\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-df62f55a-b032-484a-9a48-fb962f8108d6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving aps_failure_training_set.csv to aps_failure_training_set.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVlOcQoEvHSW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "outputId": "091d60c1-62c9-40dd-f6ae-6124c9a710fd"
      },
      "source": [
        "import io\n",
        "df = pd.read_csv(io.BytesIO(uploaded['aps_failure_training_set.csv']), sep=\",\")\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>aa_000</th>\n",
              "      <th>ab_000</th>\n",
              "      <th>ac_000</th>\n",
              "      <th>ad_000</th>\n",
              "      <th>ae_000</th>\n",
              "      <th>af_000</th>\n",
              "      <th>ag_000</th>\n",
              "      <th>ag_001</th>\n",
              "      <th>ag_002</th>\n",
              "      <th>ag_003</th>\n",
              "      <th>ag_004</th>\n",
              "      <th>ag_005</th>\n",
              "      <th>ag_006</th>\n",
              "      <th>ag_007</th>\n",
              "      <th>ag_008</th>\n",
              "      <th>ag_009</th>\n",
              "      <th>ah_000</th>\n",
              "      <th>ai_000</th>\n",
              "      <th>aj_000</th>\n",
              "      <th>ak_000</th>\n",
              "      <th>al_000</th>\n",
              "      <th>am_0</th>\n",
              "      <th>an_000</th>\n",
              "      <th>ao_000</th>\n",
              "      <th>ap_000</th>\n",
              "      <th>aq_000</th>\n",
              "      <th>ar_000</th>\n",
              "      <th>as_000</th>\n",
              "      <th>at_000</th>\n",
              "      <th>au_000</th>\n",
              "      <th>av_000</th>\n",
              "      <th>ax_000</th>\n",
              "      <th>ay_000</th>\n",
              "      <th>ay_001</th>\n",
              "      <th>ay_002</th>\n",
              "      <th>ay_003</th>\n",
              "      <th>ay_004</th>\n",
              "      <th>ay_005</th>\n",
              "      <th>ay_006</th>\n",
              "      <th>...</th>\n",
              "      <th>db_000</th>\n",
              "      <th>dc_000</th>\n",
              "      <th>dd_000</th>\n",
              "      <th>de_000</th>\n",
              "      <th>df_000</th>\n",
              "      <th>dg_000</th>\n",
              "      <th>dh_000</th>\n",
              "      <th>di_000</th>\n",
              "      <th>dj_000</th>\n",
              "      <th>dk_000</th>\n",
              "      <th>dl_000</th>\n",
              "      <th>dm_000</th>\n",
              "      <th>dn_000</th>\n",
              "      <th>do_000</th>\n",
              "      <th>dp_000</th>\n",
              "      <th>dq_000</th>\n",
              "      <th>dr_000</th>\n",
              "      <th>ds_000</th>\n",
              "      <th>dt_000</th>\n",
              "      <th>du_000</th>\n",
              "      <th>dv_000</th>\n",
              "      <th>dx_000</th>\n",
              "      <th>dy_000</th>\n",
              "      <th>dz_000</th>\n",
              "      <th>ea_000</th>\n",
              "      <th>eb_000</th>\n",
              "      <th>ec_00</th>\n",
              "      <th>ed_000</th>\n",
              "      <th>ee_000</th>\n",
              "      <th>ee_001</th>\n",
              "      <th>ee_002</th>\n",
              "      <th>ee_003</th>\n",
              "      <th>ee_004</th>\n",
              "      <th>ee_005</th>\n",
              "      <th>ee_006</th>\n",
              "      <th>ee_007</th>\n",
              "      <th>ee_008</th>\n",
              "      <th>ee_009</th>\n",
              "      <th>ef_000</th>\n",
              "      <th>eg_000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neg</td>\n",
              "      <td>76698</td>\n",
              "      <td>na</td>\n",
              "      <td>2130706438</td>\n",
              "      <td>280</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>37250</td>\n",
              "      <td>1432864</td>\n",
              "      <td>3664156</td>\n",
              "      <td>1007684</td>\n",
              "      <td>25896</td>\n",
              "      <td>0</td>\n",
              "      <td>2551696</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4933296</td>\n",
              "      <td>3655166</td>\n",
              "      <td>1766008</td>\n",
              "      <td>1132040</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1012</td>\n",
              "      <td>268</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>469014</td>\n",
              "      <td>4239660</td>\n",
              "      <td>...</td>\n",
              "      <td>18</td>\n",
              "      <td>5330690</td>\n",
              "      <td>4732</td>\n",
              "      <td>1126</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>62282</td>\n",
              "      <td>85908</td>\n",
              "      <td>32790</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>202710</td>\n",
              "      <td>37928</td>\n",
              "      <td>14745580</td>\n",
              "      <td>1876644</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2801180</td>\n",
              "      <td>2445.8</td>\n",
              "      <td>2712</td>\n",
              "      <td>965866</td>\n",
              "      <td>1706908</td>\n",
              "      <td>1240520</td>\n",
              "      <td>493384</td>\n",
              "      <td>721044</td>\n",
              "      <td>469792</td>\n",
              "      <td>339156</td>\n",
              "      <td>157956</td>\n",
              "      <td>73224</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neg</td>\n",
              "      <td>33058</td>\n",
              "      <td>na</td>\n",
              "      <td>0</td>\n",
              "      <td>na</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18254</td>\n",
              "      <td>653294</td>\n",
              "      <td>1720800</td>\n",
              "      <td>516724</td>\n",
              "      <td>31642</td>\n",
              "      <td>0</td>\n",
              "      <td>1393352</td>\n",
              "      <td>0</td>\n",
              "      <td>68</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2560898</td>\n",
              "      <td>2127150</td>\n",
              "      <td>1084598</td>\n",
              "      <td>338544</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>71510</td>\n",
              "      <td>772720</td>\n",
              "      <td>...</td>\n",
              "      <td>na</td>\n",
              "      <td>na</td>\n",
              "      <td>3312</td>\n",
              "      <td>522</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>33736</td>\n",
              "      <td>36946</td>\n",
              "      <td>5936</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>103330</td>\n",
              "      <td>16254</td>\n",
              "      <td>4510080</td>\n",
              "      <td>868538</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3477820</td>\n",
              "      <td>2211.76</td>\n",
              "      <td>2334</td>\n",
              "      <td>664504</td>\n",
              "      <td>824154</td>\n",
              "      <td>421400</td>\n",
              "      <td>178064</td>\n",
              "      <td>293306</td>\n",
              "      <td>245416</td>\n",
              "      <td>133654</td>\n",
              "      <td>81140</td>\n",
              "      <td>97576</td>\n",
              "      <td>1500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neg</td>\n",
              "      <td>41040</td>\n",
              "      <td>na</td>\n",
              "      <td>228</td>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1648</td>\n",
              "      <td>370592</td>\n",
              "      <td>1883374</td>\n",
              "      <td>292936</td>\n",
              "      <td>12016</td>\n",
              "      <td>0</td>\n",
              "      <td>1234132</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2371990</td>\n",
              "      <td>2173634</td>\n",
              "      <td>300796</td>\n",
              "      <td>153698</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>358</td>\n",
              "      <td>110</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>870456</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>2341048</td>\n",
              "      <td>1494</td>\n",
              "      <td>152</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13876</td>\n",
              "      <td>38182</td>\n",
              "      <td>8138</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>65772</td>\n",
              "      <td>10534</td>\n",
              "      <td>300240</td>\n",
              "      <td>48028</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1040120</td>\n",
              "      <td>1018.64</td>\n",
              "      <td>1020</td>\n",
              "      <td>262032</td>\n",
              "      <td>453378</td>\n",
              "      <td>277378</td>\n",
              "      <td>159812</td>\n",
              "      <td>423992</td>\n",
              "      <td>409564</td>\n",
              "      <td>320746</td>\n",
              "      <td>158022</td>\n",
              "      <td>95128</td>\n",
              "      <td>514</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neg</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>70</td>\n",
              "      <td>66</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>318</td>\n",
              "      <td>2212</td>\n",
              "      <td>3232</td>\n",
              "      <td>1872</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2668</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>642</td>\n",
              "      <td>3894</td>\n",
              "      <td>10184</td>\n",
              "      <td>7554</td>\n",
              "      <td>10764</td>\n",
              "      <td>1014</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>2578</td>\n",
              "      <td>76</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>232</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2014</td>\n",
              "      <td>370</td>\n",
              "      <td>48</td>\n",
              "      <td>18</td>\n",
              "      <td>15740</td>\n",
              "      <td>1822</td>\n",
              "      <td>20174</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.08</td>\n",
              "      <td>54</td>\n",
              "      <td>5670</td>\n",
              "      <td>1566</td>\n",
              "      <td>240</td>\n",
              "      <td>46</td>\n",
              "      <td>58</td>\n",
              "      <td>44</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neg</td>\n",
              "      <td>60874</td>\n",
              "      <td>na</td>\n",
              "      <td>1368</td>\n",
              "      <td>458</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>43752</td>\n",
              "      <td>1966618</td>\n",
              "      <td>1800340</td>\n",
              "      <td>131646</td>\n",
              "      <td>4588</td>\n",
              "      <td>0</td>\n",
              "      <td>1974038</td>\n",
              "      <td>0</td>\n",
              "      <td>226</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3230626</td>\n",
              "      <td>2618878</td>\n",
              "      <td>1058136</td>\n",
              "      <td>551022</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1788</td>\n",
              "      <td>642</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>42124</td>\n",
              "      <td>372236</td>\n",
              "      <td>2128914</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>3590004</td>\n",
              "      <td>2026</td>\n",
              "      <td>444</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>44946</td>\n",
              "      <td>62648</td>\n",
              "      <td>11506</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>149474</td>\n",
              "      <td>35154</td>\n",
              "      <td>457040</td>\n",
              "      <td>80482</td>\n",
              "      <td>98334</td>\n",
              "      <td>27588</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21173050</td>\n",
              "      <td>1116.06</td>\n",
              "      <td>1176</td>\n",
              "      <td>404740</td>\n",
              "      <td>904230</td>\n",
              "      <td>622012</td>\n",
              "      <td>229790</td>\n",
              "      <td>405298</td>\n",
              "      <td>347188</td>\n",
              "      <td>286954</td>\n",
              "      <td>311560</td>\n",
              "      <td>433954</td>\n",
              "      <td>1218</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59995</th>\n",
              "      <td>neg</td>\n",
              "      <td>153002</td>\n",
              "      <td>na</td>\n",
              "      <td>664</td>\n",
              "      <td>186</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2564</td>\n",
              "      <td>59100</td>\n",
              "      <td>1603216</td>\n",
              "      <td>6015982</td>\n",
              "      <td>1968266</td>\n",
              "      <td>164972</td>\n",
              "      <td>12560</td>\n",
              "      <td>4880368</td>\n",
              "      <td>0</td>\n",
              "      <td>280</td>\n",
              "      <td>0</td>\n",
              "      <td>1224</td>\n",
              "      <td>2114</td>\n",
              "      <td>8913782</td>\n",
              "      <td>7998174</td>\n",
              "      <td>1929126</td>\n",
              "      <td>776370</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3328</td>\n",
              "      <td>1080</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>45114</td>\n",
              "      <td>2533260</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1872932</td>\n",
              "      <td>4936</td>\n",
              "      <td>1600</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>62846</td>\n",
              "      <td>137050</td>\n",
              "      <td>27546</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>265640</td>\n",
              "      <td>54496</td>\n",
              "      <td>470800</td>\n",
              "      <td>293652</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>80125300</td>\n",
              "      <td>2912.04</td>\n",
              "      <td>2858</td>\n",
              "      <td>1608808</td>\n",
              "      <td>1479066</td>\n",
              "      <td>998500</td>\n",
              "      <td>566884</td>\n",
              "      <td>1290398</td>\n",
              "      <td>1218244</td>\n",
              "      <td>1019768</td>\n",
              "      <td>717762</td>\n",
              "      <td>898642</td>\n",
              "      <td>28588</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59996</th>\n",
              "      <td>neg</td>\n",
              "      <td>2286</td>\n",
              "      <td>na</td>\n",
              "      <td>2130706538</td>\n",
              "      <td>224</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>104</td>\n",
              "      <td>99186</td>\n",
              "      <td>36564</td>\n",
              "      <td>128</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>56982</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>123604</td>\n",
              "      <td>108768</td>\n",
              "      <td>24020</td>\n",
              "      <td>11622</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>192</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4610</td>\n",
              "      <td>99120</td>\n",
              "      <td>...</td>\n",
              "      <td>10</td>\n",
              "      <td>124152</td>\n",
              "      <td>114</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1066</td>\n",
              "      <td>808</td>\n",
              "      <td>600</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2450</td>\n",
              "      <td>510</td>\n",
              "      <td>823720</td>\n",
              "      <td>82346</td>\n",
              "      <td>16440</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1285980</td>\n",
              "      <td>80.4</td>\n",
              "      <td>82</td>\n",
              "      <td>13934</td>\n",
              "      <td>15024</td>\n",
              "      <td>10578</td>\n",
              "      <td>6760</td>\n",
              "      <td>21126</td>\n",
              "      <td>68424</td>\n",
              "      <td>136</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59997</th>\n",
              "      <td>neg</td>\n",
              "      <td>112</td>\n",
              "      <td>0</td>\n",
              "      <td>2130706432</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>11592</td>\n",
              "      <td>11538</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8784</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>29698</td>\n",
              "      <td>23762</td>\n",
              "      <td>13970</td>\n",
              "      <td>874</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>8864</td>\n",
              "      <td>148</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>7042</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>622</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4544</td>\n",
              "      <td>2398</td>\n",
              "      <td>162</td>\n",
              "      <td>58</td>\n",
              "      <td>7920</td>\n",
              "      <td>784</td>\n",
              "      <td>9112</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.76</td>\n",
              "      <td>134</td>\n",
              "      <td>15876</td>\n",
              "      <td>2740</td>\n",
              "      <td>792</td>\n",
              "      <td>386</td>\n",
              "      <td>452</td>\n",
              "      <td>144</td>\n",
              "      <td>146</td>\n",
              "      <td>2622</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59998</th>\n",
              "      <td>neg</td>\n",
              "      <td>80292</td>\n",
              "      <td>na</td>\n",
              "      <td>2130706432</td>\n",
              "      <td>494</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>330</td>\n",
              "      <td>202498</td>\n",
              "      <td>3251010</td>\n",
              "      <td>2061456</td>\n",
              "      <td>360436</td>\n",
              "      <td>59754</td>\n",
              "      <td>2634394</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4543410</td>\n",
              "      <td>3227856</td>\n",
              "      <td>1615634</td>\n",
              "      <td>1214970</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>57300</td>\n",
              "      <td>0</td>\n",
              "      <td>2124</td>\n",
              "      <td>1090</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>119742</td>\n",
              "      <td>4445146</td>\n",
              "      <td>...</td>\n",
              "      <td>22</td>\n",
              "      <td>4858834</td>\n",
              "      <td>5598</td>\n",
              "      <td>284</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>190</td>\n",
              "      <td>106152</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>79230</td>\n",
              "      <td>37162</td>\n",
              "      <td>18388</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>166748</td>\n",
              "      <td>40564</td>\n",
              "      <td>25232340</td>\n",
              "      <td>5648346</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>39881280</td>\n",
              "      <td>1659.7</td>\n",
              "      <td>1908</td>\n",
              "      <td>1180714</td>\n",
              "      <td>1709450</td>\n",
              "      <td>699352</td>\n",
              "      <td>222654</td>\n",
              "      <td>347378</td>\n",
              "      <td>225724</td>\n",
              "      <td>194440</td>\n",
              "      <td>165070</td>\n",
              "      <td>802280</td>\n",
              "      <td>388422</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59999</th>\n",
              "      <td>neg</td>\n",
              "      <td>40222</td>\n",
              "      <td>na</td>\n",
              "      <td>698</td>\n",
              "      <td>628</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1226</td>\n",
              "      <td>46284</td>\n",
              "      <td>1901140</td>\n",
              "      <td>855376</td>\n",
              "      <td>61744</td>\n",
              "      <td>6318</td>\n",
              "      <td>1235850</td>\n",
              "      <td>1926</td>\n",
              "      <td>474</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2502090</td>\n",
              "      <td>2109168</td>\n",
              "      <td>573660</td>\n",
              "      <td>334864</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2260</td>\n",
              "      <td>266</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>105702</td>\n",
              "      <td>1433988</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>2506446</td>\n",
              "      <td>2116</td>\n",
              "      <td>214</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21454</td>\n",
              "      <td>25034</td>\n",
              "      <td>4644</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>79872</td>\n",
              "      <td>14390</td>\n",
              "      <td>152740</td>\n",
              "      <td>17080</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>39221060</td>\n",
              "      <td>1035.22</td>\n",
              "      <td>1256</td>\n",
              "      <td>409798</td>\n",
              "      <td>686416</td>\n",
              "      <td>440066</td>\n",
              "      <td>183200</td>\n",
              "      <td>344546</td>\n",
              "      <td>254068</td>\n",
              "      <td>225148</td>\n",
              "      <td>158304</td>\n",
              "      <td>170384</td>\n",
              "      <td>158</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60000 rows × 171 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      class  aa_000 ab_000      ac_000  ...  ee_008  ee_009 ef_000 eg_000\n",
              "0       neg   76698     na  2130706438  ...   73224       0      0      0\n",
              "1       neg   33058     na           0  ...   97576    1500      0      0\n",
              "2       neg   41040     na         228  ...   95128     514      0      0\n",
              "3       neg      12      0          70  ...       0       0      4     32\n",
              "4       neg   60874     na        1368  ...  433954    1218      0      0\n",
              "...     ...     ...    ...         ...  ...     ...     ...    ...    ...\n",
              "59995   neg  153002     na         664  ...  898642   28588      0      0\n",
              "59996   neg    2286     na  2130706538  ...       0       0      0      0\n",
              "59997   neg     112      0  2130706432  ...       0       0      0      0\n",
              "59998   neg   80292     na  2130706432  ...  802280  388422      0      0\n",
              "59999   neg   40222     na         698  ...  170384     158      0      0\n",
              "\n",
              "[60000 rows x 171 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2XlQSaBvNRs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.replace(to_replace = 'na', value = np.NaN, inplace = True)\n",
        "df.replace(to_replace = 'neg', value = 0, inplace = True)\n",
        "df.replace(to_replace = 'pos', value = 1, inplace = True)\n",
        "\n",
        "X_all = df.drop(['class', 'aa_000', 'ab_000', 'ac_000', 'ad_000', 'ae_000', 'af_000', 'ah_000', 'ai_000', 'aj_000', 'ak_000', 'al_000', 'am_0', 'an_000', 'ao_000', 'ap_000', 'aq_000', 'ar_000', 'as_000', 'at_000', 'au_000', 'av_000', 'ax_000', 'bb_000', 'bc_000', 'bd_000', 'be_000', 'bf_000', 'bg_000', 'bh_000', 'bi_000', 'bj_000', 'bk_000', 'bl_000', 'bm_000', 'bn_000', 'bo_000', 'bp_000', 'bq_000', 'br_000', 'bs_000', 'bt_000', 'bu_000', 'bv_000', 'bx_000', 'by_000', 'bz_000', 'ca_000', 'cb_000', 'cc_000', 'cd_000', 'ce_000', 'cf_000', 'cg_000', 'ch_000', 'ci_000', 'cj_000', 'ck_000', 'cl_000', 'cm_000', 'co_000', 'cp_000', 'cq_000', 'cr_000', 'ct_000', 'cu_000', 'cv_000', 'cx_000', 'cy_000', 'cz_000', 'da_000', 'db_000', 'dc_000', 'dd_000', 'de_000', 'df_000', 'dg_000', 'dh_000', 'di_000', 'dj_000', 'dk_000', 'dl_000', 'dm_000', 'dn_000', 'do_000', 'dp_000', 'dq_000', 'dr_000', 'ds_000', 'dt_000', 'du_000', 'dv_000', 'dx_000', 'dy_000', 'dz_000', 'ea_000', 'eb_000', 'ec_00', 'ed_000', 'ef_000', 'eg_000'], axis = 1)\n",
        "y_all = df['class']\n",
        "\n",
        "train = X_all\n",
        "cols = train.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k34qJMVXvXSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#STANDARD IMPUTATIONS\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "#KNN\n",
        "knn_imputer = KNNImputer(n_neighbors=5)\n",
        "knn_imputed = knn_imputer.fit_transform(train)\n",
        "\n",
        "#transpose knn\n",
        "knn_list = list()\n",
        "knn_list.append(knn_imputed)\n",
        "\n",
        "a= {}\n",
        "cnt=0\n",
        "for i in knn_list:\n",
        "    i.transpose()\n",
        "    i= np.array(i).transpose()\n",
        "    for j in i:\n",
        "        a[cols[cnt]]=j\n",
        "        cnt=cnt+1  \n",
        "knnDFn = pd.DataFrame(a)\n",
        "\n",
        "#MEAN\n",
        "mean_imputer = SimpleImputer(strategy='mean')\n",
        "mean_imputed = mean_imputer.fit_transform(train)\n",
        "#transpose mean\n",
        "mean_list = list()\n",
        "mean_list.append(mean_imputed)\n",
        "\n",
        "b= {}\n",
        "cnt=0\n",
        "for i in mean_list:\n",
        "    i.transpose()\n",
        "    i= np.array(i).transpose()\n",
        "    for j in i:\n",
        "        b[cols[cnt]]=j\n",
        "        cnt=cnt+1  \n",
        "meanDFn = pd.DataFrame(b)\n",
        "\n",
        "\n",
        "#MEDIAN\n",
        "median_imputer = SimpleImputer(strategy='median')\n",
        "median_imputed = median_imputer.fit_transform(train)\n",
        "\n",
        "#transpose median\n",
        "median_list = list()\n",
        "median_list.append(median_imputed)\n",
        "\n",
        "c= {}\n",
        "cnt=0\n",
        "for i in median_list:\n",
        "    i.transpose()\n",
        "    i= np.array(i).transpose()\n",
        "    for j in i:\n",
        "        c[cols[cnt]]=j\n",
        "        cnt=cnt+1  \n",
        "medianDFn = pd.DataFrame(c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEtEVWbnEE_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#THIS IS THE NORMALIZATION CELL for MEDIAN\n",
        "#CREATE A LIST OF ALL HISTOGRAMS\n",
        "median_df = medianDFn\n",
        "cols = medianDFn.columns\n",
        "medianlist_hist = list()\n",
        "mediantemporary_list = list()\n",
        "for i, j in enumerate(cols[:-1]):\n",
        "\n",
        "  first_column = j\n",
        "  next_column = cols[i+1]\n",
        "  if  i == (len(cols)-2):\n",
        "    if first_column[0:2] == next_column[0:2]:\n",
        "      mediantemporary_list.append(median_df[first_column])\n",
        "      mediantemporary_list.append(median_df[next_column])\n",
        "      medianlist_hist.append(mediantemporary_list) \n",
        "    \n",
        "    else:\n",
        "      mediantemporary_list.append(median_df[first_column])\n",
        "      medianlist_hist.append(mediantemporary_list) \n",
        "      #throwing the old temporary away and create a new empty \"temporary list\"\n",
        "      mediantemporary_list = list()\n",
        "      mediantemporary_list.append(median_df[next_column])\n",
        "      medianlist_hist.append(mediantemporary_list) \n",
        "\n",
        "  elif first_column[0:2] == next_column[0:2]:\n",
        "    mediantemporary_list.append(median_df[first_column])\n",
        "\n",
        "  else: \n",
        "    #add the last column to the temporary list\n",
        "    mediantemporary_list.append(median_df[first_column])\n",
        "    medianlist_hist.append(mediantemporary_list) \n",
        "    #throwing the old temporary away and create a new empty \"temporary list\"\n",
        "    mediantemporary_list = list()\n",
        "\n",
        "\n",
        "#CREATE NEW LIST AND REPLACE THE ITEMS WITH THEIR WEIGHTS\n",
        "medianlist_hist2 = list()\n",
        "\n",
        "for histogram in medianlist_hist:\n",
        "  sum = 0\n",
        "  for item in histogram:\n",
        "    sum += item\n",
        "  for item in histogram:\n",
        "    j=item\n",
        "    for index, itemsItem in enumerate(item):\n",
        "      if sum[index]==0:\n",
        "        j[index] = itemsItem\n",
        "      else:\n",
        "        j[index] = itemsItem/sum[index]\n",
        "  \n",
        "    medianlist_hist2.append(j)\n",
        "\n",
        "#TRANSPOSE THE LIST TO A DATAFRAME ONCE AGAIN\n",
        "medianDF = pd.DataFrame(np.transpose(medianlist_hist2),columns=cols)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6PglS_tElzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#THIS IS THE NORMALIZATION CELL for MEAN\n",
        "#CREATE A LIST OF ALL HISTOGRAMS\n",
        "mean_df = meanDFn\n",
        "cols = meanDFn.columns\n",
        "meanlist_hist = list()\n",
        "meantemporary_list = list()\n",
        "for i, j in enumerate(cols[:-1]):\n",
        "\n",
        "  first_column = j\n",
        "  next_column = cols[i+1]\n",
        "  if  i == (len(cols)-2):\n",
        "    if first_column[0:2] == next_column[0:2]:\n",
        "      meantemporary_list.append(mean_df[first_column])\n",
        "      meantemporary_list.append(mean_df[next_column])\n",
        "      meanlist_hist.append(meantemporary_list) \n",
        "    \n",
        "    else:\n",
        "      meantemporary_list.append(mean_df[first_column])\n",
        "      meanlist_hist.append(meantemporary_list) \n",
        "      #throwing the old temporary away and create a new empty \"temporary list\"\n",
        "      meantemporary_list = list()\n",
        "      meantemporary_list.append(mean_df[next_column])\n",
        "      meanlist_hist.append(meantemporary_list) \n",
        "\n",
        "  elif first_column[0:2] == next_column[0:2]:\n",
        "    meantemporary_list.append(mean_df[first_column])\n",
        "\n",
        "  else: \n",
        "    #add the last column to the temporary list\n",
        "    meantemporary_list.append(mean_df[first_column])\n",
        "    meanlist_hist.append(meantemporary_list) \n",
        "    #throwing the old temporary away and create a new empty \"temporary list\"\n",
        "    meantemporary_list = list()\n",
        "\n",
        "\n",
        "#CREATE NEW LIST AND REPLACE THE ITEMS WITH THEIR WEIGHTS\n",
        "meanlist_hist2 = list()\n",
        "\n",
        "for histogram in meanlist_hist:\n",
        "  sum = 0\n",
        "  for item in histogram:\n",
        "    sum += item\n",
        "  for item in histogram:\n",
        "    j=item\n",
        "    for index, itemsItem in enumerate(item):\n",
        "      if sum[index]==0:\n",
        "        j[index] = itemsItem\n",
        "      else:\n",
        "        j[index] = itemsItem/sum[index]\n",
        "  \n",
        "    meanlist_hist2.append(j)\n",
        "\n",
        "#TRANSPOSE THE LIST TO A DATAFRAME ONCE AGAIN\n",
        "meanDF = pd.DataFrame(np.transpose(meanlist_hist2),columns=cols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ng-rl6GiZ7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#THIS IS THE NORMALIZATION CELL for KNN\n",
        "#CREATE A LIST OF ALL HISTOGRAMS\n",
        "knn_df = knnDFn\n",
        "cols = knnDFn.columns\n",
        "knnlist_hist = list()\n",
        "knntemporary_list = list()\n",
        "for i, j in enumerate(cols[:-1]):\n",
        "\n",
        "  first_column = j\n",
        "  next_column = cols[i+1]\n",
        "  if  i == (len(cols)-2):\n",
        "    if first_column[0:2] == next_column[0:2]:\n",
        "      knntemporary_list.append(knn_df[first_column])\n",
        "      knntemporary_list.append(knn_df[next_column])\n",
        "      knnlist_hist.append(knntemporary_list) \n",
        "    \n",
        "    else:\n",
        "      knntemporary_list.append(knn_df[first_column])\n",
        "      knnlist_hist.append(knntemporary_list) \n",
        "      #throwing the old temporary away and create a new empty \"temporary list\"\n",
        "      knntemporary_list = list()\n",
        "      knntemporary_list.append(knn_df[next_column])\n",
        "      knnlist_hist.append(knntemporary_list) \n",
        "\n",
        "  elif first_column[0:2] == next_column[0:2]:\n",
        "    knntemporary_list.append(knn_df[first_column])\n",
        "\n",
        "  else: \n",
        "    #add the last column to the temporary list\n",
        "    knntemporary_list.append(knn_df[first_column])\n",
        "    knnlist_hist.append(knntemporary_list) \n",
        "    #throwing the old temporary away and create a new empty \"temporary list\"\n",
        "    knntemporary_list = list()\n",
        "\n",
        "\n",
        "#CREATE NEW LIST AND REPLACE THE ITEMS WITH THEIR WEIGHTS\n",
        "knnlist_hist2 = list()\n",
        "\n",
        "for histogram in knnlist_hist:\n",
        "  sum = 0\n",
        "  for item in histogram:\n",
        "    sum += item\n",
        "  for item in histogram:\n",
        "    j=item\n",
        "    for index, itemsItem in enumerate(item):\n",
        "      if sum[index]==0:\n",
        "        j[index] = itemsItem\n",
        "      else:\n",
        "        j[index] = itemsItem/sum[index]\n",
        "  \n",
        "    knnlist_hist2.append(j)\n",
        "\n",
        "#TRANSPOSE THE LIST TO A DATAFRAME ONCE AGAIN\n",
        "knnDF = pd.DataFrame(np.transpose(knnlist_hist2),columns=cols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Has91zavOxT3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "69bdbce2-0ade-4b8f-c7ab-b7b248ba614b"
      },
      "source": [
        "medianDF.equals(knnDF)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcFh69tCFeGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "meanDF_scaled = scaler.fit_transform(meanDFn)\n",
        "medianDF_scaled = scaler.fit_transform(medianDFn)\n",
        "knnDF_scaled = scaler.fit_transform(knnDFn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8gqcDg53ZDb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "d197ba65-634d-4217-f90b-351017a482e6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-edf45e5fa8af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmeanDF_scaled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeanDF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'equals'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SazMsI6av7ec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#KNN_1.0\n",
        "\n",
        "#PREPROCESS\n",
        "df = train\n",
        "cols = df.columns\n",
        "list_hist = list()\n",
        "temporary_list = list()\n",
        "for i, j in enumerate(cols[:-1]):\n",
        "\n",
        "  first_column = j\n",
        "  next_column = cols[i+1]\n",
        "  if  i == (len(cols)-2):\n",
        "    if first_column[0:2] == next_column[0:2]:\n",
        "      temporary_list.append(df[first_column])\n",
        "      temporary_list.append(df[next_column])\n",
        "      list_hist.append(temporary_list) \n",
        "    \n",
        "    else:\n",
        "      temporary_list.append(df[first_column])\n",
        "      list_hist.append(temporary_list) \n",
        "      #throwing the old temporary away and create a new empty \"temporary list\"\n",
        "      temporary_list = list()\n",
        "      temporary_list.append(df[next_column])\n",
        "      list_hist.append(temporary_list) \n",
        "\n",
        "  elif first_column[0:2] == next_column[0:2]:\n",
        "    temporary_list.append(df[first_column])\n",
        "\n",
        "  else: \n",
        "    #add the last column to the temporary list\n",
        "    temporary_list.append(df[first_column])\n",
        "    list_hist.append(temporary_list) \n",
        "    #throwing the old temporary away and create a new empty \"temporary list\"\n",
        "    temporary_list = list()\n",
        "\n",
        "list_hist2 = list()\n",
        "temp_list = list()\n",
        "for histogram in list_hist:\n",
        "  temp_list= list()\n",
        "  for column_index, column in enumerate(histogram):    \n",
        "    for row_index, row in enumerate(column):\n",
        "      if column_index == 0:\n",
        "        l = list()\n",
        "        l.append(row)\n",
        "        temp_list.append(l)\n",
        "      else:\n",
        "        temp_list[row_index].append(row)\n",
        "    list_hist2.append(temp_list)\n",
        "\n",
        "list_of_vectors_in_many_histograms = []\n",
        "for word in list_hist2:\n",
        "    if word not in list_of_vectors_in_many_histograms:\n",
        "        list_of_vectors_in_many_histograms.append(word)\n",
        "\n",
        "list_of_vectors_in_one_list = []\n",
        "for index, i in enumerate(list_of_vectors_in_many_histograms):\n",
        "  for index, j in enumerate(i):\n",
        "    list_of_vectors_in_one_list.append(j)\n",
        "\n",
        "from sklearn.impute import KNNImputer\n",
        "imputer = KNNImputer(n_neighbors=5)\n",
        "KNN_1 = imputer.fit_transform(list_of_vectors_in_one_list)\n",
        "\n",
        "cols = X_all.columns\n",
        "e = pd.DataFrame(KNN_1)\n",
        "e1 = pd.DataFrame(e.iloc[0:60000])\n",
        "e1= e1.reset_index(drop=True)\n",
        "e2 = pd.DataFrame(e.iloc[60000:120000])\n",
        "e2 = e2.reset_index(drop=True)\n",
        "e3 = pd.DataFrame(e.iloc[120000:180000])\n",
        "e3 = e3.reset_index(drop=True)\n",
        "e4 = pd.DataFrame(e.iloc[180000:240000])\n",
        "e4 = e4.reset_index(drop=True)\n",
        "e5 = pd.DataFrame(e.iloc[240000:300000])\n",
        "e5 = e5.reset_index(drop=True)\n",
        "e6 = pd.DataFrame(e.iloc[300000:360000])\n",
        "e6 = e6.reset_index(drop=True)\n",
        "e7 = pd.DataFrame(e.iloc[360000:420000])\n",
        "e7 = e7.reset_index(drop=True)\n",
        "\n",
        "knn_onen = pd.concat([e1,e2, e3, e4, e5, e6, e7], axis=1, sort=False)\n",
        "knn_onen.columns = [np.arange(0,knn_onen.shape[1])]\n",
        "knn_onen.columns = ['ag_000', 'ag_001', 'ag_002', 'ag_003', 'ag_004', 'ag_005', 'ag_006',\n",
        "       'ag_007', 'ag_008', 'ag_009', 'ay_000', 'ay_001', 'ay_002', 'ay_003',\n",
        "       'ay_004', 'ay_005', 'ay_006', 'ay_007', 'ay_008', 'ay_009', 'az_000',\n",
        "       'az_001', 'az_002', 'az_003', 'az_004', 'az_005', 'az_006', 'az_007',\n",
        "       'az_008', 'az_009', 'ba_000', 'ba_001', 'ba_002', 'ba_003', 'ba_004',\n",
        "       'ba_005', 'ba_006', 'ba_007', 'ba_008', 'ba_009', 'cn_000', 'cn_001',\n",
        "       'cn_002', 'cn_003', 'cn_004', 'cn_005', 'cn_006', 'cn_007', 'cn_008',\n",
        "       'cn_009', 'cs_000', 'cs_001', 'cs_002', 'cs_003', 'cs_004', 'cs_005',\n",
        "       'cs_006', 'cs_007', 'cs_008', 'cs_009', 'ee_000', 'ee_001', 'ee_002',\n",
        "       'ee_003', 'ee_004', 'ee_005', 'ee_006', 'ee_007', 'ee_008', 'ee_009']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7KIWChBGZAy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#THIS IS THE NORMALIZATION CELL for KNN_1.0\n",
        "#CREATE A LIST OF ALL HISTOGRAMS\n",
        "knn1_df = knn_onen\n",
        "cols = knn_onen.columns\n",
        "knn1list_hist = list()\n",
        "knn1temporary_list = list()\n",
        "for i, j in enumerate(cols[:-1]):\n",
        "\n",
        "  first_column = j\n",
        "  next_column = cols[i+1]\n",
        "  if  i == (len(cols)-2):\n",
        "    if first_column[0:2] == next_column[0:2]:\n",
        "      knn1temporary_list.append(knn1_df[first_column])\n",
        "      knn1temporary_list.append(knn1_df[next_column])\n",
        "      knn1list_hist.append(knn1temporary_list) \n",
        "    \n",
        "    else:\n",
        "      knn1temporary_list.append(knn1_df[first_column])\n",
        "      knn1list_hist.append(knn1temporary_list) \n",
        "      #throwing the old temporary away and create a new empty \"temporary list\"\n",
        "      knn1temporary_list = list()\n",
        "      knn1temporary_list.append(knn1_df[next_column])\n",
        "      knn1list_hist.append(knn1temporary_list) \n",
        "\n",
        "  elif first_column[0:2] == next_column[0:2]:\n",
        "    knn1temporary_list.append(knn1_df[first_column])\n",
        "\n",
        "  else: \n",
        "    #add the last column to the temporary list\n",
        "    knn1temporary_list.append(knn1_df[first_column])\n",
        "    knn1list_hist.append(knn1temporary_list) \n",
        "    #throwing the old temporary away and create a new empty \"temporary list\"\n",
        "    knn1temporary_list = list()\n",
        "\n",
        "\n",
        "#CREATE NEW LIST AND REPLACE THE ITEMS WITH THEIR WEIGHTS\n",
        "knn1list_hist2 = list()\n",
        "\n",
        "for histogram in knn1list_hist:\n",
        "  sum = 0\n",
        "  for item in histogram:\n",
        "    sum += item\n",
        "  for item in histogram:\n",
        "    j=item\n",
        "    for index, itemsItem in enumerate(item):\n",
        "      if sum[index]==0:\n",
        "        j[index] = itemsItem\n",
        "      else:\n",
        "        j[index] = itemsItem/sum[index]\n",
        "  \n",
        "    knn1list_hist2.append(j)\n",
        "\n",
        "#TRANSPOSE THE LIST TO A DATAFRAME ONCE AGAIN\n",
        "knn_one = pd.DataFrame(np.transpose(knn1list_hist2),columns=cols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDGPAnAzxbV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#KNN_2.0\n",
        "\n",
        "df1 = X_all.transpose()\n",
        "\n",
        "temporary_list= list()\n",
        "final_hist_list= list()\n",
        "counter=0\n",
        "for i in range(len(df1.columns)):\n",
        "    counter=0\n",
        "    temp=cols[0][:2]\n",
        "    for j in cols:\n",
        "        if temp!=j[:2]:\n",
        "            counter=counter+1\n",
        "            final_hist_list.append(temporary_list)\n",
        "            temporary_list= list()\n",
        "            temp = j[:2]\n",
        "        temporary_list.append(df1[i][j])\n",
        "    final_hist_list.append(temporary_list)\n",
        "    temporary_list=list()\n",
        "    counter=counter+1\n",
        "\n",
        "i=0\n",
        "\n",
        "last_hist_list=list()\n",
        "for i in range(counter):\n",
        "    last_hist_list.append([])\n",
        "i=0    \n",
        "while i < len(final_hist_list):\n",
        "    for j in range(counter):\n",
        "        last_hist_list[j].append(final_hist_list[i])\n",
        "        i=i+1 \n",
        "        \n",
        "from sklearn.impute import KNNImputer\n",
        "imputer = KNNImputer(n_neighbors=5)\n",
        "for i in range(counter):\n",
        "    last_hist_list[i] = imputer.fit_transform(last_hist_list[i])\n",
        "\n",
        "u= {}\n",
        "cnty=0\n",
        "for i in last_hist_list:\n",
        "    i.transpose()\n",
        "    i= np.array(i).transpose()\n",
        "    for j in i:\n",
        "        u[cols[cnty]]=j\n",
        "        cnty=cnty+1    \n",
        "knn_twon = pd.DataFrame(u)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_BzRfBYHFB9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#THIS IS THE NORMALIZATION CELL for KNN_2.0\n",
        "#CREATE A LIST OF ALL HISTOGRAMS\n",
        "knn2_df = knn_twon\n",
        "cols = knn_twon.columns\n",
        "knn2list_hist = list()\n",
        "knn2temporary_list = list()\n",
        "for i, j in enumerate(cols[:-1]):\n",
        "\n",
        "  first_column = j\n",
        "  next_column = cols[i+1]\n",
        "  if  i == (len(cols)-2):\n",
        "    if first_column[0:2] == next_column[0:2]:\n",
        "      knn2temporary_list.append(knn2_df[first_column])\n",
        "      knn2temporary_list.append(knn2_df[next_column])\n",
        "      knn2list_hist.append(knn2temporary_list) \n",
        "    \n",
        "    else:\n",
        "      knn2temporary_list.append(knn2_df[first_column])\n",
        "      knn2list_hist.append(knn2temporary_list) \n",
        "      #throwing the old temporary away and create a new empty \"temporary list\"\n",
        "      knn2temporary_list = list()\n",
        "      knn2temporary_list.append(knn2_df[next_column])\n",
        "      knn2list_hist.append(knn2temporary_list) \n",
        "\n",
        "  elif first_column[0:2] == next_column[0:2]:\n",
        "    knn2temporary_list.append(knn2_df[first_column])\n",
        "\n",
        "  else: \n",
        "    #add the last column to the temporary list\n",
        "    knn2temporary_list.append(knn2_df[first_column])\n",
        "    knn2list_hist.append(knn2temporary_list) \n",
        "    #throwing the old temporary away and create a new empty \"temporary list\"\n",
        "    knn2temporary_list = list()\n",
        "\n",
        "\n",
        "#CREATE NEW LIST AND REPLACE THE ITEMS WITH THEIR WEIGHTS\n",
        "knn2list_hist2 = list()\n",
        "\n",
        "for histogram in knn2list_hist:\n",
        "  sum = 0\n",
        "  for item in histogram:\n",
        "    sum += item\n",
        "  for item in histogram:\n",
        "    j=item\n",
        "    for index, itemsItem in enumerate(item):\n",
        "      if sum[index]==0:\n",
        "        j[index] = itemsItem\n",
        "      else:\n",
        "        j[index] = itemsItem/sum[index]\n",
        "  \n",
        "    knn2list_hist2.append(j)\n",
        "\n",
        "#TRANSPOSE THE LIST TO A DATAFRAME ONCE AGAIN\n",
        "knn_two = pd.DataFrame(np.transpose(knn2list_hist2),columns=cols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0svvpavuHcIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SCALE KNN_1.0 and 2.0 as well.\n",
        "\n",
        "knn_one_scaled = scaler.fit_transform(knn_onen)\n",
        "knn_two_scaled = scaler.fit_transform(knn_twon)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFqiY35eg8gC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "knn = knnDF.values\n",
        "mean = meanDF.values\n",
        "median = medianDF.values\n",
        "knn1 = knn_one.values\n",
        "knn2 = knn_two.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1F60dm3N9eK3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e3b1f9da-f3db-46c5-bd1b-d745c65d00d4"
      },
      "source": [
        "knn_two.equals(knnDF)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6aEys1exG_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Xknn_train, Xknn_test, yknn_train, yknn_test = train_test_split (knnDF, y_all, \n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 10)\n",
        "\n",
        "Xknnv_train, Xknnv_test, yknnv_train, yknnv_test = train_test_split (knn, y_all, \n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 10)\n",
        "\n",
        "Xknnsc_train, Xknnsc_test, yknnsc_train, yknnsc_test = train_test_split (knnDF_scaled, y_all, \n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 10)\n",
        "\n",
        "Xmean_train, Xmean_test, ymean_train, ymean_test = train_test_split (meanDF, y_all, \n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 10)\n",
        "\n",
        "Xmeanv_train, Xmeanv_test, ymeanv_train, ymeanv_test = train_test_split (mean, y_all, \n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 10)\n",
        "\n",
        "Xmeansc_train, Xmeansc_test, ymeansc_train, ymeansc_test = train_test_split (meanDF_scaled, y_all, \n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 10)\n",
        "\n",
        "Xmedian_train, Xmedian_test, ymedian_train, ymedian_test = train_test_split (medianDF, y_all, \n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 10)\n",
        "\n",
        "Xmedianv_train, Xmedianv_test, ymedianv_train, ymedianv_test = train_test_split (median, y_all, \n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 10)\n",
        "\n",
        "Xmediansc_train, Xmediansc_test, ymediansc_train, ymediansc_test = train_test_split (medianDF_scaled, y_all, \n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 10)\n",
        "\n",
        "Xknn1_train, Xknn1_test, yknn1_train, yknn1_test = train_test_split (knn_one, y_all, \n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 10)\n",
        "\n",
        "Xknn1sc_train, Xknn1sc_test, yknn1sc_train, yknn1sc_test = train_test_split (knn_one_scaled, y_all, \n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 10)\n",
        "\n",
        "Xknn1v_train, Xknn1v_test, yknn1v_train, yknn1v_test = train_test_split (knn1, y_all, \n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 10)\n",
        "\n",
        "Xknn2_train, Xknn2_test, yknn2_train, yknn2_test = train_test_split (knn_two, y_all, \n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 10)\n",
        "\n",
        "Xknn2v_train, Xknn2v_test, yknn2v_train, yknn2v_test = train_test_split (knn2, y_all, \n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 10)\n",
        "\n",
        "Xknn2sc_train, Xknn2sc_test, yknn2sc_train, yknn2sc_test = train_test_split (knn_two_scaled, y_all, \n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DedWqbD61HAT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "outputId": "c6e97c4e-39c6-4d6d-b15c-401727371f98"
      },
      "source": [
        "Xknn1_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ag_000</th>\n",
              "      <th>ag_001</th>\n",
              "      <th>ag_002</th>\n",
              "      <th>ag_003</th>\n",
              "      <th>ag_004</th>\n",
              "      <th>ag_005</th>\n",
              "      <th>ag_006</th>\n",
              "      <th>ag_007</th>\n",
              "      <th>ag_008</th>\n",
              "      <th>ag_009</th>\n",
              "      <th>ay_000</th>\n",
              "      <th>ay_001</th>\n",
              "      <th>ay_002</th>\n",
              "      <th>ay_003</th>\n",
              "      <th>ay_004</th>\n",
              "      <th>ay_005</th>\n",
              "      <th>ay_006</th>\n",
              "      <th>ay_007</th>\n",
              "      <th>ay_008</th>\n",
              "      <th>ay_009</th>\n",
              "      <th>az_000</th>\n",
              "      <th>az_001</th>\n",
              "      <th>az_002</th>\n",
              "      <th>az_003</th>\n",
              "      <th>az_004</th>\n",
              "      <th>az_005</th>\n",
              "      <th>az_006</th>\n",
              "      <th>az_007</th>\n",
              "      <th>az_008</th>\n",
              "      <th>az_009</th>\n",
              "      <th>ba_000</th>\n",
              "      <th>ba_001</th>\n",
              "      <th>ba_002</th>\n",
              "      <th>ba_003</th>\n",
              "      <th>ba_004</th>\n",
              "      <th>ba_005</th>\n",
              "      <th>ba_006</th>\n",
              "      <th>ba_007</th>\n",
              "      <th>ba_008</th>\n",
              "      <th>ba_009</th>\n",
              "      <th>cn_000</th>\n",
              "      <th>cn_001</th>\n",
              "      <th>cn_002</th>\n",
              "      <th>cn_003</th>\n",
              "      <th>cn_004</th>\n",
              "      <th>cn_005</th>\n",
              "      <th>cn_006</th>\n",
              "      <th>cn_007</th>\n",
              "      <th>cn_008</th>\n",
              "      <th>cn_009</th>\n",
              "      <th>cs_000</th>\n",
              "      <th>cs_001</th>\n",
              "      <th>cs_002</th>\n",
              "      <th>cs_003</th>\n",
              "      <th>cs_004</th>\n",
              "      <th>cs_005</th>\n",
              "      <th>cs_006</th>\n",
              "      <th>cs_007</th>\n",
              "      <th>cs_008</th>\n",
              "      <th>cs_009</th>\n",
              "      <th>ee_000</th>\n",
              "      <th>ee_001</th>\n",
              "      <th>ee_002</th>\n",
              "      <th>ee_003</th>\n",
              "      <th>ee_004</th>\n",
              "      <th>ee_005</th>\n",
              "      <th>ee_006</th>\n",
              "      <th>ee_007</th>\n",
              "      <th>ee_008</th>\n",
              "      <th>ee_009</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4883</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000928</td>\n",
              "      <td>0.038185</td>\n",
              "      <td>0.692368</td>\n",
              "      <td>0.268519</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.713536</td>\n",
              "      <td>0.286440</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000781</td>\n",
              "      <td>0.000220</td>\n",
              "      <td>0.000317</td>\n",
              "      <td>0.000684</td>\n",
              "      <td>0.465159</td>\n",
              "      <td>0.532814</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.479418</td>\n",
              "      <td>0.427413</td>\n",
              "      <td>0.073710</td>\n",
              "      <td>0.018263</td>\n",
              "      <td>0.000977</td>\n",
              "      <td>0.000220</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004004</td>\n",
              "      <td>0.530617</td>\n",
              "      <td>0.429855</td>\n",
              "      <td>0.031276</td>\n",
              "      <td>0.003882</td>\n",
              "      <td>0.000366</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001758</td>\n",
              "      <td>0.000317</td>\n",
              "      <td>0.017017</td>\n",
              "      <td>0.049441</td>\n",
              "      <td>0.015235</td>\n",
              "      <td>0.668221</td>\n",
              "      <td>0.236681</td>\n",
              "      <td>0.011304</td>\n",
              "      <td>2.441525e-05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.114166</td>\n",
              "      <td>0.099834</td>\n",
              "      <td>0.041872</td>\n",
              "      <td>0.017140</td>\n",
              "      <td>0.131842</td>\n",
              "      <td>0.589897</td>\n",
              "      <td>0.005200</td>\n",
              "      <td>0.000049</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28477</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004096</td>\n",
              "      <td>0.096604</td>\n",
              "      <td>0.507164</td>\n",
              "      <td>0.360359</td>\n",
              "      <td>0.030442</td>\n",
              "      <td>0.001235</td>\n",
              "      <td>0.000099</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000941</td>\n",
              "      <td>0.005569</td>\n",
              "      <td>0.005195</td>\n",
              "      <td>0.010077</td>\n",
              "      <td>0.038201</td>\n",
              "      <td>0.380645</td>\n",
              "      <td>0.187122</td>\n",
              "      <td>0.372249</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000698</td>\n",
              "      <td>0.000351</td>\n",
              "      <td>0.000494</td>\n",
              "      <td>0.007344</td>\n",
              "      <td>0.512243</td>\n",
              "      <td>0.478672</td>\n",
              "      <td>0.000199</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.307268</td>\n",
              "      <td>0.293808</td>\n",
              "      <td>0.138094</td>\n",
              "      <td>0.073352</td>\n",
              "      <td>0.047378</td>\n",
              "      <td>0.035634</td>\n",
              "      <td>0.034815</td>\n",
              "      <td>0.065189</td>\n",
              "      <td>0.004463</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000668</td>\n",
              "      <td>0.034247</td>\n",
              "      <td>0.334858</td>\n",
              "      <td>0.450857</td>\n",
              "      <td>0.163772</td>\n",
              "      <td>0.013496</td>\n",
              "      <td>0.001834</td>\n",
              "      <td>0.000266</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.001332</td>\n",
              "      <td>0.000171</td>\n",
              "      <td>0.005722</td>\n",
              "      <td>0.056640</td>\n",
              "      <td>0.027552</td>\n",
              "      <td>0.658493</td>\n",
              "      <td>0.237874</td>\n",
              "      <td>0.012129</td>\n",
              "      <td>8.500838e-05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.116196</td>\n",
              "      <td>0.133751</td>\n",
              "      <td>0.126063</td>\n",
              "      <td>0.092381</td>\n",
              "      <td>0.281978</td>\n",
              "      <td>0.153044</td>\n",
              "      <td>0.085530</td>\n",
              "      <td>0.010801</td>\n",
              "      <td>0.000256</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8527</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38347</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000057</td>\n",
              "      <td>0.110901</td>\n",
              "      <td>0.598996</td>\n",
              "      <td>0.255264</td>\n",
              "      <td>0.032375</td>\n",
              "      <td>0.002406</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.018360</td>\n",
              "      <td>0.492276</td>\n",
              "      <td>0.468266</td>\n",
              "      <td>0.021099</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000719</td>\n",
              "      <td>0.000443</td>\n",
              "      <td>0.000439</td>\n",
              "      <td>0.023311</td>\n",
              "      <td>0.767771</td>\n",
              "      <td>0.207300</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.372273</td>\n",
              "      <td>0.198454</td>\n",
              "      <td>0.074963</td>\n",
              "      <td>0.065166</td>\n",
              "      <td>0.062595</td>\n",
              "      <td>0.068369</td>\n",
              "      <td>0.136818</td>\n",
              "      <td>0.021362</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003264</td>\n",
              "      <td>0.233585</td>\n",
              "      <td>0.560513</td>\n",
              "      <td>0.187578</td>\n",
              "      <td>0.013182</td>\n",
              "      <td>0.001790</td>\n",
              "      <td>0.000088</td>\n",
              "      <td>0.001291</td>\n",
              "      <td>0.000145</td>\n",
              "      <td>0.026314</td>\n",
              "      <td>0.083467</td>\n",
              "      <td>0.050880</td>\n",
              "      <td>0.502888</td>\n",
              "      <td>0.331414</td>\n",
              "      <td>0.003574</td>\n",
              "      <td>2.752237e-05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.186403</td>\n",
              "      <td>0.192093</td>\n",
              "      <td>0.122083</td>\n",
              "      <td>0.054553</td>\n",
              "      <td>0.097001</td>\n",
              "      <td>0.072864</td>\n",
              "      <td>0.074881</td>\n",
              "      <td>0.065768</td>\n",
              "      <td>0.129534</td>\n",
              "      <td>0.004819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3363</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010774</td>\n",
              "      <td>0.432453</td>\n",
              "      <td>0.492612</td>\n",
              "      <td>0.060410</td>\n",
              "      <td>0.003752</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008492</td>\n",
              "      <td>0.352646</td>\n",
              "      <td>0.229060</td>\n",
              "      <td>0.409803</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000308</td>\n",
              "      <td>0.000089</td>\n",
              "      <td>0.000261</td>\n",
              "      <td>0.056955</td>\n",
              "      <td>0.841705</td>\n",
              "      <td>0.100667</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.270126</td>\n",
              "      <td>0.195141</td>\n",
              "      <td>0.102808</td>\n",
              "      <td>0.093934</td>\n",
              "      <td>0.092554</td>\n",
              "      <td>0.096476</td>\n",
              "      <td>0.129761</td>\n",
              "      <td>0.019200</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000121</td>\n",
              "      <td>0.058997</td>\n",
              "      <td>0.485120</td>\n",
              "      <td>0.355643</td>\n",
              "      <td>0.088873</td>\n",
              "      <td>0.009369</td>\n",
              "      <td>0.001758</td>\n",
              "      <td>0.000120</td>\n",
              "      <td>0.000957</td>\n",
              "      <td>0.000124</td>\n",
              "      <td>0.000776</td>\n",
              "      <td>0.098827</td>\n",
              "      <td>0.034927</td>\n",
              "      <td>0.294999</td>\n",
              "      <td>0.567899</td>\n",
              "      <td>0.001492</td>\n",
              "      <td>1.416228e-07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.138354</td>\n",
              "      <td>0.136050</td>\n",
              "      <td>0.094136</td>\n",
              "      <td>0.049117</td>\n",
              "      <td>0.103341</td>\n",
              "      <td>0.088013</td>\n",
              "      <td>0.088877</td>\n",
              "      <td>0.076980</td>\n",
              "      <td>0.210917</td>\n",
              "      <td>0.014215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51525</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000709</td>\n",
              "      <td>0.299673</td>\n",
              "      <td>0.603909</td>\n",
              "      <td>0.094092</td>\n",
              "      <td>0.001618</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000686</td>\n",
              "      <td>0.535690</td>\n",
              "      <td>0.247097</td>\n",
              "      <td>0.216528</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000638</td>\n",
              "      <td>0.000367</td>\n",
              "      <td>0.000565</td>\n",
              "      <td>0.001655</td>\n",
              "      <td>0.266305</td>\n",
              "      <td>0.729963</td>\n",
              "      <td>0.000506</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.511955</td>\n",
              "      <td>0.144267</td>\n",
              "      <td>0.095734</td>\n",
              "      <td>0.072346</td>\n",
              "      <td>0.067718</td>\n",
              "      <td>0.052656</td>\n",
              "      <td>0.047200</td>\n",
              "      <td>0.008124</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000337</td>\n",
              "      <td>0.085248</td>\n",
              "      <td>0.557601</td>\n",
              "      <td>0.317489</td>\n",
              "      <td>0.035501</td>\n",
              "      <td>0.003260</td>\n",
              "      <td>0.000565</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000814</td>\n",
              "      <td>0.000173</td>\n",
              "      <td>0.043882</td>\n",
              "      <td>0.033902</td>\n",
              "      <td>0.059102</td>\n",
              "      <td>0.764809</td>\n",
              "      <td>0.090138</td>\n",
              "      <td>0.007180</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.146018</td>\n",
              "      <td>0.149282</td>\n",
              "      <td>0.102769</td>\n",
              "      <td>0.063385</td>\n",
              "      <td>0.188227</td>\n",
              "      <td>0.237144</td>\n",
              "      <td>0.090857</td>\n",
              "      <td>0.019195</td>\n",
              "      <td>0.003124</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17051</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.026316</td>\n",
              "      <td>0.255748</td>\n",
              "      <td>0.670878</td>\n",
              "      <td>0.047058</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.018301</td>\n",
              "      <td>0.981699</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.013684</td>\n",
              "      <td>0.002309</td>\n",
              "      <td>0.002084</td>\n",
              "      <td>0.003773</td>\n",
              "      <td>0.077879</td>\n",
              "      <td>0.900272</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.604674</td>\n",
              "      <td>0.316640</td>\n",
              "      <td>0.055467</td>\n",
              "      <td>0.008428</td>\n",
              "      <td>0.004843</td>\n",
              "      <td>0.002440</td>\n",
              "      <td>0.001933</td>\n",
              "      <td>0.004242</td>\n",
              "      <td>0.001145</td>\n",
              "      <td>0.000188</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.026222</td>\n",
              "      <td>0.150859</td>\n",
              "      <td>0.625040</td>\n",
              "      <td>0.175204</td>\n",
              "      <td>0.020216</td>\n",
              "      <td>0.001933</td>\n",
              "      <td>0.000526</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.012839</td>\n",
              "      <td>0.000619</td>\n",
              "      <td>0.021286</td>\n",
              "      <td>0.055974</td>\n",
              "      <td>0.140272</td>\n",
              "      <td>0.703444</td>\n",
              "      <td>0.065565</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.492783</td>\n",
              "      <td>0.185453</td>\n",
              "      <td>0.050343</td>\n",
              "      <td>0.013646</td>\n",
              "      <td>0.018939</td>\n",
              "      <td>0.031966</td>\n",
              "      <td>0.037597</td>\n",
              "      <td>0.169273</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42068</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001034</td>\n",
              "      <td>0.040573</td>\n",
              "      <td>0.846169</td>\n",
              "      <td>0.110728</td>\n",
              "      <td>0.001497</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006069</td>\n",
              "      <td>0.440728</td>\n",
              "      <td>0.553203</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001278</td>\n",
              "      <td>0.000596</td>\n",
              "      <td>0.000632</td>\n",
              "      <td>0.003564</td>\n",
              "      <td>0.510343</td>\n",
              "      <td>0.482712</td>\n",
              "      <td>0.000874</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.253822</td>\n",
              "      <td>0.298255</td>\n",
              "      <td>0.118909</td>\n",
              "      <td>0.091338</td>\n",
              "      <td>0.071143</td>\n",
              "      <td>0.055926</td>\n",
              "      <td>0.051678</td>\n",
              "      <td>0.058038</td>\n",
              "      <td>0.000890</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001519</td>\n",
              "      <td>0.264608</td>\n",
              "      <td>0.662480</td>\n",
              "      <td>0.065263</td>\n",
              "      <td>0.004655</td>\n",
              "      <td>0.001427</td>\n",
              "      <td>0.000047</td>\n",
              "      <td>0.001797</td>\n",
              "      <td>0.000222</td>\n",
              "      <td>0.003945</td>\n",
              "      <td>0.042562</td>\n",
              "      <td>0.019616</td>\n",
              "      <td>0.689741</td>\n",
              "      <td>0.232839</td>\n",
              "      <td>0.009160</td>\n",
              "      <td>1.182444e-04</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.072048</td>\n",
              "      <td>0.181821</td>\n",
              "      <td>0.156130</td>\n",
              "      <td>0.105115</td>\n",
              "      <td>0.311996</td>\n",
              "      <td>0.144764</td>\n",
              "      <td>0.025569</td>\n",
              "      <td>0.002552</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52063</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000232</td>\n",
              "      <td>0.114155</td>\n",
              "      <td>0.662339</td>\n",
              "      <td>0.221300</td>\n",
              "      <td>0.001975</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001274</td>\n",
              "      <td>0.016785</td>\n",
              "      <td>0.015002</td>\n",
              "      <td>0.027620</td>\n",
              "      <td>0.035322</td>\n",
              "      <td>0.345886</td>\n",
              "      <td>0.295033</td>\n",
              "      <td>0.263078</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004241</td>\n",
              "      <td>0.000084</td>\n",
              "      <td>0.000212</td>\n",
              "      <td>0.000291</td>\n",
              "      <td>0.002967</td>\n",
              "      <td>0.992175</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.351602</td>\n",
              "      <td>0.543568</td>\n",
              "      <td>0.069868</td>\n",
              "      <td>0.025355</td>\n",
              "      <td>0.005919</td>\n",
              "      <td>0.002226</td>\n",
              "      <td>0.001323</td>\n",
              "      <td>0.000138</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.035692</td>\n",
              "      <td>0.497880</td>\n",
              "      <td>0.413419</td>\n",
              "      <td>0.049371</td>\n",
              "      <td>0.003145</td>\n",
              "      <td>0.000494</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004808</td>\n",
              "      <td>0.000128</td>\n",
              "      <td>0.001145</td>\n",
              "      <td>0.081489</td>\n",
              "      <td>0.013324</td>\n",
              "      <td>0.648758</td>\n",
              "      <td>0.242083</td>\n",
              "      <td>0.008062</td>\n",
              "      <td>2.024022e-04</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.116919</td>\n",
              "      <td>0.099207</td>\n",
              "      <td>0.069108</td>\n",
              "      <td>0.039928</td>\n",
              "      <td>0.454383</td>\n",
              "      <td>0.200279</td>\n",
              "      <td>0.009918</td>\n",
              "      <td>0.009967</td>\n",
              "      <td>0.000291</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40328</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006165</td>\n",
              "      <td>0.530606</td>\n",
              "      <td>0.436865</td>\n",
              "      <td>0.026364</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.076842</td>\n",
              "      <td>0.923158</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.030933</td>\n",
              "      <td>0.003082</td>\n",
              "      <td>0.003953</td>\n",
              "      <td>0.004279</td>\n",
              "      <td>0.034740</td>\n",
              "      <td>0.923013</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.644619</td>\n",
              "      <td>0.157057</td>\n",
              "      <td>0.157492</td>\n",
              "      <td>0.019437</td>\n",
              "      <td>0.008123</td>\n",
              "      <td>0.001994</td>\n",
              "      <td>0.001342</td>\n",
              "      <td>0.009501</td>\n",
              "      <td>0.000435</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.032782</td>\n",
              "      <td>0.431208</td>\n",
              "      <td>0.465659</td>\n",
              "      <td>0.050080</td>\n",
              "      <td>0.020271</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.025094</td>\n",
              "      <td>0.001052</td>\n",
              "      <td>0.006129</td>\n",
              "      <td>0.037750</td>\n",
              "      <td>0.028104</td>\n",
              "      <td>0.840985</td>\n",
              "      <td>0.060886</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.531259</td>\n",
              "      <td>0.156150</td>\n",
              "      <td>0.043879</td>\n",
              "      <td>0.008921</td>\n",
              "      <td>0.021758</td>\n",
              "      <td>0.015992</td>\n",
              "      <td>0.026327</td>\n",
              "      <td>0.195714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12000 rows × 70 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       ag_000  ag_001  ag_002    ag_003  ...    ee_006    ee_007    ee_008    ee_009\n",
              "4883      0.0     0.0     0.0  0.000000  ...  0.005200  0.000049  0.000000  0.000000\n",
              "28477     0.0     0.0     0.0  0.004096  ...  0.085530  0.010801  0.000256  0.000000\n",
              "8527      0.0     0.0     0.0  0.000000  ...  0.000000  0.000000  0.000000  0.000000\n",
              "38347     0.0     0.0     0.0  0.000000  ...  0.074881  0.065768  0.129534  0.004819\n",
              "3363      0.0     0.0     0.0  0.000000  ...  0.088877  0.076980  0.210917  0.014215\n",
              "...       ...     ...     ...       ...  ...       ...       ...       ...       ...\n",
              "51525     0.0     0.0     0.0  0.000000  ...  0.090857  0.019195  0.003124  0.000000\n",
              "17051     0.0     0.0     0.0  0.026316  ...  0.037597  0.169273  0.000000  0.000000\n",
              "42068     0.0     0.0     0.0  0.000000  ...  0.025569  0.002552  0.000005  0.000000\n",
              "52063     0.0     0.0     0.0  0.000000  ...  0.009918  0.009967  0.000291  0.000000\n",
              "40328     0.0     0.0     0.0  0.006165  ...  0.026327  0.195714  0.000000  0.000000\n",
              "\n",
              "[12000 rows x 70 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPoEy2Jf4qCN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "a072c4d9-60b5-4bee-b5d2-98653a478eee"
      },
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "# Initialize the three models (XGBoost is initialized later)\n",
        "clf_A = LogisticRegression(solver='sag', random_state = 42, max_iter=1000000)\n",
        "clf_B = SVC(probability=True, random_state = 912, kernel='rbf')\n",
        "#Boosting refers to this general problem of producing a very accurate prediction rule \n",
        "#by combining rough and moderately inaccurate rules-of-thumb\n",
        "clf_C = xgb.XGBClassifier()\n",
        "clf_D = RandomForestClassifier(n_estimators = 128, max_depth=50)\n",
        "\n",
        "#hist_norm data\n",
        "\n",
        "clf_A.fit(Xknn_train, yknn_train)\n",
        "clf_B.fit(Xknn_train, yknn_train)\n",
        "clf_C.fit(Xknnv_train, yknnv_train)\n",
        "clf_D.fit(Xknn_train, yknn_train)\n",
        "\n",
        "clf_A.fit(Xmean_train, ymean_train)\n",
        "clf_B.fit(Xmean_train, ymean_train)\n",
        "clf_C.fit(Xmeanv_train, ymeanv_train)\n",
        "clf_D.fit(Xmean_train, ymean_train)\n",
        "\n",
        "clf_A.fit(Xmedian_train, ymedian_train)\n",
        "clf_B.fit(Xmedian_train, ymedian_train)\n",
        "clf_C.fit(Xmedianv_train, ymedianv_train)\n",
        "clf_D.fit(Xmedian_train, ymedian_train)\n",
        "\n",
        "clf_A.fit(Xknn1_train, yknn1_train)\n",
        "clf_B.fit(Xknn1_train, yknn1_train)\n",
        "clf_C.fit(Xknn1v_train, yknn1v_train)\n",
        "clf_D.fit(Xknn1_train, yknn1_train)\n",
        "\n",
        "clf_A.fit(Xknn2_train, yknn2_train)\n",
        "clf_B.fit(Xknn2_train, yknn2_train)\n",
        "clf_C.fit(Xknn2v_train, yknn2v_train)\n",
        "clf_D.fit(Xknn2_train, yknn2_train)\n",
        "\n",
        "# scaled data\n",
        "clf_A.fit(Xknnsc_train, yknnsc_train)\n",
        "clf_B.fit(Xknnsc_train, yknnsc_train)\n",
        "clf_C.fit(Xknnsc_train, yknnsc_train)\n",
        "clf_D.fit(Xknnsc_train, yknnsc_train)\n",
        "\n",
        "clf_A.fit(Xmeansc_train, ymeansc_train)\n",
        "clf_B.fit(Xmeansc_train, ymeansc_train)\n",
        "clf_C.fit(Xmeansc_train, ymeansc_train)\n",
        "clf_D.fit(Xmeansc_train, ymeansc_train)\n",
        "\n",
        "clf_A.fit(Xmediansc_train, ymediansc_train)\n",
        "clf_B.fit(Xmediansc_train, ymediansc_train)\n",
        "clf_C.fit(Xmediansc_train, ymediansc_train)\n",
        "clf_D.fit(Xmediansc_train, ymediansc_train)\n",
        "\n",
        "clf_A.fit(Xknn1sc_train, yknn1sc_train)\n",
        "clf_B.fit(Xknn1sc_train, yknn1sc_train)\n",
        "clf_C.fit(Xknn1sc_train, yknn1sc_train)\n",
        "clf_D.fit(Xknn1sc_train, yknn1sc_train)\n",
        "\n",
        "clf_A.fit(Xknn2sc_train, yknn2sc_train)\n",
        "clf_B.fit(Xknn2sc_train, yknn2sc_train)\n",
        "clf_C.fit(Xknn2sc_train, yknn2sc_train)\n",
        "clf_D.fit(Xknn2sc_train, yknn2sc_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=50, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=128,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FogeuiCKqbib",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "18e8a5e4-a33f-4fcc-c3db-6357f674ece7"
      },
      "source": [
        "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
        "knn_lr_pred = clf_A.predict(Xknn_test)\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn_test, knn_lr_pred,zero_division=1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision Score: 1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28AscCsg5n_1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e252ed70-a2d8-4172-c2de-f623fd1d9e4f"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
        "\n",
        "\n",
        "#********KNN_histnorm******************\n",
        "\n",
        "#AUC\n",
        "knn_lr_probs = clf_A.predict_proba(Xknn_test)\n",
        "knn_svm_probs = clf_B.predict_proba(Xknn_test)\n",
        "knn_xgb_probs = clf_C.predict_proba(Xknnv_test)\n",
        "knn_rf_probs = clf_D.predict_proba(Xknn_test)\n",
        "# keep probabilities for the positive outcome only\n",
        "knn_lr_probs = knn_lr_probs[:, 1]\n",
        "knn_svm_probs = knn_svm_probs[:, 1]\n",
        "knn_xgb_probs = knn_xgb_probs[:, 1]\n",
        "knn_rf_probs = knn_rf_probs[:, 1]\n",
        "# calculate scores\n",
        "knn_lr_auc = roc_auc_score(yknn_test, knn_lr_probs)\n",
        "knn_svm_auc = roc_auc_score(yknn_test, knn_svm_probs)\n",
        "knn_xgb_auc = roc_auc_score(yknnv_test, knn_xgb_probs)\n",
        "knn_rf_auc = roc_auc_score(yknn_test, knn_rf_probs)\n",
        "\n",
        "# OTHER METRICS for standard KNN\n",
        "knn_lr_pred = clf_A.predict(Xknn_test)\n",
        "knn_s_pred = clf_B.predict(Xknn_test)\n",
        "knn_x_pred = clf_C.predict(Xknnv_test)\n",
        "knn_rf_pred = clf_D.predict(Xknn_test)\n",
        "\n",
        "\n",
        "#********KNN_scaled******************\n",
        "\n",
        "#AUC\n",
        "knnsc_lr_probs = clf_A.predict_proba(Xknnsc_test)\n",
        "knnsc_svm_probs = clf_B.predict_proba(Xknnsc_test)\n",
        "knnsc_xgb_probs = clf_C.predict_proba(Xknnsc_test)\n",
        "knnsc_rf_probs = clf_D.predict_proba(Xknnsc_test)\n",
        "# keep probabilities for the positive outcome only\n",
        "knnsc_lr_probs = knnsc_lr_probs[:, 1]\n",
        "knnsc_svm_probs = knnsc_svm_probs[:, 1]\n",
        "knnsc_xgb_probs = knnsc_xgb_probs[:, 1]\n",
        "knnsc_rf_probs = knnsc_rf_probs[:, 1]\n",
        "# calculate scores\n",
        "knnsc_lr_auc = roc_auc_score(yknnsc_test, knnsc_lr_probs)\n",
        "knnsc_svm_auc = roc_auc_score(yknnsc_test, knnsc_svm_probs)\n",
        "knnsc_xgb_auc = roc_auc_score(yknnsc_test, knnsc_xgb_probs)\n",
        "knnsc_rf_auc = roc_auc_score(yknnsc_test, knnsc_rf_probs)\n",
        "\n",
        "# OTHER METRICS for standard KNN\n",
        "knnsc_lr_pred = clf_A.predict(Xknnsc_test)\n",
        "knnsc_s_pred = clf_B.predict(Xknnsc_test)\n",
        "knnsc_x_pred = clf_C.predict(Xknnsc_test)\n",
        "knnsc_rf_pred = clf_D.predict(Xknnsc_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#********MEAN_histnorm******************\n",
        "\n",
        "mean_lr_probs = clf_A.predict_proba(Xmean_test)\n",
        "mean_svm_probs = clf_B.predict_proba(Xmean_test)\n",
        "mean_xgb_probs = clf_C.predict_proba(Xmeanv_test)\n",
        "mean_rf_probs = clf_D.predict_proba(Xmean_test)\n",
        "# keep probabilities for the positive outcome only\n",
        "mean_lr_probs = mean_lr_probs[:, 1]\n",
        "mean_svm_probs = mean_svm_probs[:, 1]\n",
        "mean_xgb_probs = mean_xgb_probs[:, 1]\n",
        "mean_rf_probs = mean_rf_probs[:, 1]\n",
        "# calculate scores\n",
        "mean_lr_auc = roc_auc_score(ymean_test, mean_lr_probs)\n",
        "mean_svm_auc = roc_auc_score(ymean_test, mean_svm_probs)\n",
        "mean_xgb_auc = roc_auc_score(ymeanv_test, mean_xgb_probs)\n",
        "mean_rf_auc = roc_auc_score(ymean_test, mean_rf_probs)\n",
        "\n",
        "# OTHER METRICS for standard MEAN\n",
        "mean_lr_pred = clf_A.predict(Xmean_test)\n",
        "mean_s_pred = clf_B.predict(Xmean_test)\n",
        "mean_x_pred = clf_C.predict(Xmeanv_test)\n",
        "mean_rf_pred = clf_D.predict(Xmean_test)\n",
        "\n",
        "\n",
        "#********MEAN_scaled******************\n",
        "\n",
        "meansc_lr_probs = clf_A.predict_proba(Xmeansc_test)\n",
        "meansc_svm_probs = clf_B.predict_proba(Xmeansc_test)\n",
        "meansc_xgb_probs = clf_C.predict_proba(Xmeansc_test)\n",
        "meansc_rf_probs = clf_D.predict_proba(Xmeansc_test)\n",
        "# keep probabilities for the positive outcome only\n",
        "meansc_lr_probs = meansc_lr_probs[:, 1]\n",
        "meansc_svm_probs = meansc_svm_probs[:, 1]\n",
        "meansc_xgb_probs = meansc_xgb_probs[:, 1]\n",
        "meansc_rf_probs = meansc_rf_probs[:, 1]\n",
        "# calculate scores\n",
        "meansc_lr_auc = roc_auc_score(ymeansc_test, meansc_lr_probs)\n",
        "meansc_svm_auc = roc_auc_score(ymeansc_test, meansc_svm_probs)\n",
        "meansc_xgb_auc = roc_auc_score(ymeansc_test, meansc_xgb_probs)\n",
        "meansc_rf_auc = roc_auc_score(ymeansc_test, meansc_rf_probs)\n",
        "\n",
        "# OTHER METRICS for standard MEAN\n",
        "meansc_lr_pred = clf_A.predict(Xmeansc_test)\n",
        "meansc_s_pred = clf_B.predict(Xmeansc_test)\n",
        "meansc_x_pred = clf_C.predict(Xmeansc_test)\n",
        "meansc_rf_pred = clf_D.predict(Xmeansc_test)\n",
        "\n",
        "\n",
        "\n",
        "#********MEDIAN_histnorm******************\n",
        "\n",
        "median_lr_probs = clf_A.predict_proba(Xmedian_test)\n",
        "median_svm_probs = clf_B.predict_proba(Xmedian_test)\n",
        "median_xgb_probs = clf_C.predict_proba(Xmedianv_test)\n",
        "median_rf_probs = clf_D.predict_proba(Xmedian_test)\n",
        "# keep probabilities for the positive outcome only\n",
        "median_lr_probs = median_lr_probs[:, 1]\n",
        "median_svm_probs = median_svm_probs[:, 1]\n",
        "median_xgb_probs = median_xgb_probs[:, 1]\n",
        "median_rf_probs = median_rf_probs[:, 1]\n",
        "# calculate scores\n",
        "median_lr_auc = roc_auc_score(ymedian_test, median_lr_probs)\n",
        "median_svm_auc = roc_auc_score(ymedian_test, median_svm_probs)\n",
        "median_xgb_auc = roc_auc_score(ymedianv_test, median_xgb_probs)\n",
        "median_rf_auc = roc_auc_score(ymedian_test, median_rf_probs)\n",
        "\n",
        "# OTHER METRICS for standard MEDIAN\n",
        "median_lr_pred = clf_A.predict(Xmedian_test)\n",
        "median_s_pred = clf_B.predict(Xmedian_test)\n",
        "median_x_pred = clf_C.predict(Xmedianv_test)\n",
        "median_rf_pred = clf_D.predict(Xmedian_test)\n",
        "\n",
        "\n",
        "#********MEDIAN_scaled******************\n",
        "\n",
        "mediansc_lr_probs = clf_A.predict_proba(Xmediansc_test)\n",
        "mediansc_svm_probs = clf_B.predict_proba(Xmediansc_test)\n",
        "mediansc_xgb_probs = clf_C.predict_proba(Xmediansc_test)\n",
        "mediansc_rf_probs = clf_D.predict_proba(Xmediansc_test)\n",
        "# keep probabilities for the positive outcome only\n",
        "mediansc_lr_probs = mediansc_lr_probs[:, 1]\n",
        "mediansc_svm_probs = mediansc_svm_probs[:, 1]\n",
        "mediansc_xgb_probs = mediansc_xgb_probs[:, 1]\n",
        "mediansc_rf_probs = mediansc_rf_probs[:, 1]\n",
        "# calculate scores\n",
        "mediansc_lr_auc = roc_auc_score(ymediansc_test, mediansc_lr_probs)\n",
        "mediansc_svm_auc = roc_auc_score(ymediansc_test, mediansc_svm_probs)\n",
        "mediansc_xgb_auc = roc_auc_score(ymediansc_test, mediansc_xgb_probs)\n",
        "mediansc_rf_auc = roc_auc_score(ymediansc_test, mediansc_rf_probs)\n",
        "\n",
        "# OTHER METRICS for standard MEDIAN\n",
        "mediansc_lr_pred = clf_A.predict(Xmediansc_test)\n",
        "mediansc_s_pred = clf_B.predict(Xmediansc_test)\n",
        "mediansc_x_pred = clf_C.predict(Xmediansc_test)\n",
        "mediansc_rf_pred = clf_D.predict(Xmediansc_test)\n",
        "\n",
        "\n",
        "\n",
        "#********KNN_1.0_histnorm******************\n",
        "\n",
        "#AUC\n",
        "knn1_lr_probs = clf_A.predict_proba(Xknn1_test)\n",
        "knn1_svm_probs = clf_B.predict_proba(Xknn1_test)\n",
        "knn1_xgb_probs = clf_C.predict_proba(Xknn1v_test)\n",
        "knn1_rf_probs = clf_D.predict_proba(Xknn1_test)\n",
        "# keep probabilities for the positive outcome only\n",
        "knn1_lr_probs = knn1_lr_probs[:, 1]\n",
        "knn1_svm_probs = knn1_svm_probs[:, 1]\n",
        "knn1_xgb_probs = knn1_xgb_probs[:, 1]\n",
        "knn1_rf_probs = knn1_rf_probs[:, 1]\n",
        "# calculate scores\n",
        "knn1_lr_auc = roc_auc_score(yknn1_test, knn1_lr_probs)\n",
        "knn1_svm_auc = roc_auc_score(yknn1_test, knn1_svm_probs)\n",
        "knn1_xgb_auc = roc_auc_score(yknn1v_test, knn1_xgb_probs)\n",
        "knn1_rf_auc = roc_auc_score(yknn1_test, knn1_rf_probs)\n",
        "\n",
        "# OTHER METRICS for standard KNN_1.0\n",
        "knn1_lr_pred = clf_A.predict(Xknn1_test)\n",
        "knn1_s_pred = clf_B.predict(Xknn1_test)\n",
        "knn1_x_pred = clf_C.predict(Xknn1v_test)\n",
        "knn1_rf_pred = clf_D.predict(Xknn1_test)\n",
        "\n",
        "\n",
        "#********KNN_1.0_scaled******************\n",
        "\n",
        "#AUC\n",
        "knn1sc_lr_probs = clf_A.predict_proba(Xknn1sc_test)\n",
        "knn1sc_svm_probs = clf_B.predict_proba(Xknn1sc_test)\n",
        "knn1sc_xgb_probs = clf_C.predict_proba(Xknn1sc_test)\n",
        "knn1sc_rf_probs = clf_D.predict_proba(Xknn1sc_test)\n",
        "# keep probabilities for the positive outcome only\n",
        "knn1sc_lr_probs = knn1sc_lr_probs[:, 1]\n",
        "knn1sc_svm_probs = knn1sc_svm_probs[:, 1]\n",
        "knn1sc_xgb_probs = knn1sc_xgb_probs[:, 1]\n",
        "knn1sc_rf_probs = knn1sc_rf_probs[:, 1]\n",
        "# calculate scores\n",
        "knn1sc_lr_auc = roc_auc_score(yknn1sc_test, knn1sc_lr_probs)\n",
        "knn1sc_svm_auc = roc_auc_score(yknn1sc_test, knn1sc_svm_probs)\n",
        "knn1sc_xgb_auc = roc_auc_score(yknn1sc_test, knn1sc_xgb_probs)\n",
        "knn1sc_rf_auc = roc_auc_score(yknn1sc_test, knn1sc_rf_probs)\n",
        "\n",
        "# OTHER METRICS for standard KNN_1.0\n",
        "knn1sc_lr_pred = clf_A.predict(Xknn1sc_test)\n",
        "knn1sc_s_pred = clf_B.predict(Xknn1sc_test)\n",
        "knn1sc_x_pred = clf_C.predict(Xknn1sc_test)\n",
        "knn1sc_rf_pred = clf_D.predict(Xknn1sc_test)\n",
        "\n",
        "\n",
        "#********KNN_2.0_histnorm******************\n",
        "\n",
        "#AUC\n",
        "knn2_lr_probs = clf_A.predict_proba(Xknn2_test)\n",
        "knn2_svm_probs = clf_B.predict_proba(Xknn2_test)\n",
        "knn2_xgb_probs = clf_C.predict_proba(Xknn2v_test)\n",
        "knn2_rf_probs = clf_D.predict_proba(Xknn2_test)\n",
        "# keep probabilities for the positive outcome only\n",
        "knn2_lr_probs = knn2_lr_probs[:, 1]\n",
        "knn2_svm_probs = knn2_svm_probs[:, 1]\n",
        "knn2_xgb_probs = knn2_xgb_probs[:, 1]\n",
        "knn2_rf_probs = knn2_rf_probs[:, 1]\n",
        "# calculate scores\n",
        "knn2_lr_auc = roc_auc_score(yknn2_test, knn2_lr_probs)\n",
        "knn2_svm_auc = roc_auc_score(yknn2_test, knn2_svm_probs)\n",
        "knn2_xgb_auc = roc_auc_score(yknn2v_test, knn2_xgb_probs)\n",
        "knn2_rf_auc = roc_auc_score(yknn2_test, knn2_rf_probs)\n",
        "\n",
        "# OTHER METRICS for standard KNN\n",
        "knn2_lr_pred = clf_A.predict(Xknn2_test)\n",
        "knn2_s_pred = clf_B.predict(Xknn2_test)\n",
        "knn2_x_pred = clf_C.predict(Xknn2v_test)\n",
        "knn2_rf_pred = clf_D.predict(Xknn2_test)\n",
        "\n",
        "\n",
        "#********KNN_2.0_scaled******************\n",
        "\n",
        "#AUC\n",
        "knn2sc_lr_probs = clf_A.predict_proba(Xknn2sc_test)\n",
        "knn2sc_svm_probs = clf_B.predict_proba(Xknn2sc_test)\n",
        "knn2sc_xgb_probs = clf_C.predict_proba(Xknn2sc_test)\n",
        "knn2sc_rf_probs = clf_D.predict_proba(Xknn2sc_test)\n",
        "# keep probabilities for the positive outcome only\n",
        "knn2sc_lr_probs = knn2sc_lr_probs[:, 1]\n",
        "knn2sc_svm_probs = knn2sc_svm_probs[:, 1]\n",
        "knn2sc_xgb_probs = knn2sc_xgb_probs[:, 1]\n",
        "knn2sc_rf_probs = knn2sc_rf_probs[:, 1]\n",
        "# calculate scores\n",
        "knn2sc_lr_auc = roc_auc_score(yknn2sc_test, knn2sc_lr_probs)\n",
        "knn2sc_svm_auc = roc_auc_score(yknn2sc_test, knn2sc_svm_probs)\n",
        "knn2sc_xgb_auc = roc_auc_score(yknn2sc_test, knn2sc_xgb_probs)\n",
        "knn2sc_rf_auc = roc_auc_score(yknn2sc_test, knn2sc_rf_probs)\n",
        "\n",
        "# OTHER METRICS for standard KNN\n",
        "knn2sc_lr_pred = clf_A.predict(Xknn2sc_test)\n",
        "knn2sc_s_pred = clf_B.predict(Xknn2sc_test)\n",
        "knn2sc_x_pred = clf_C.predict(Xknn2sc_test)\n",
        "knn2sc_rf_pred = clf_D.predict(Xknn2sc_test)\n",
        "\n",
        "print ('KNN with hist_norm')\n",
        "print ('LOGISTIC REGRESSION')\n",
        "print('AUC score: %.3f' % (knn_lr_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn_test, knn_lr_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn_test, knn_lr_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn_test, knn_lr_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn_test, knn_lr_pred)))\n",
        "print('')\n",
        "print ('SVM')\n",
        "print('AUC score: %.3f' % (knn_svm_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn_test, knn_s_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn_test, knn_s_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn_test, knn_s_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn_test, knn_s_pred)))\n",
        "print('')\n",
        "print ('XGBOOST')\n",
        "print('AUC score: %.3f' % (knn_xgb_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknnv_test, knn_x_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknnv_test, knn_x_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknnv_test, knn_x_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknnv_test, knn_x_pred)))\n",
        "print('')\n",
        "print ('RANDOM FOREST')\n",
        "print('AUC score: %.3f' % (knn_rf_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn_test, knn_rf_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn_test, knn_rf_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn_test, knn_rf_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn_test, knn_rf_pred)))\n",
        "print('')\n",
        "print('')\n",
        "print('')\n",
        "print ('MEAN with hist_norm')\n",
        "print ('LOGISTIC REGRESSION')\n",
        "print('AUC score: %.3f' % (mean_lr_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymean_test, mean_lr_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymean_test, mean_lr_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymean_test, mean_lr_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymean_test, mean_lr_pred)))\n",
        "print('')\n",
        "print ('SVM')\n",
        "print('AUC score: %.3f' % (mean_svm_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymean_test, mean_s_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymean_test, mean_s_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymean_test, mean_s_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymean_test, mean_s_pred)))\n",
        "print('')\n",
        "print ('XGBOOST')\n",
        "print('AUC score: %.3f' % (mean_xgb_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymeanv_test, mean_x_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymeanv_test, mean_x_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymeanv_test, mean_x_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymeanv_test, mean_x_pred)))\n",
        "print('')\n",
        "print ('RANDOM FOREST')\n",
        "print('AUC score: %.3f' % (mean_rf_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymean_test, mean_rf_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymean_test, mean_rf_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymean_test, mean_rf_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymean_test, mean_rf_pred)))\n",
        "print('')\n",
        "print('')\n",
        "print('')\n",
        "print ('MEDIAN with hist_norm')\n",
        "print ('LOGISTIC REGRESSION')\n",
        "print('AUC score: %.3f' % (median_lr_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymedian_test, median_lr_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymedian_test, median_lr_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymedian_test, median_lr_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymedian_test, median_lr_pred)))\n",
        "print('')\n",
        "print ('SVM')\n",
        "print('AUC score: %.3f' % (median_svm_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymedian_test, median_s_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymedian_test, median_s_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymedian_test, median_s_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymedian_test, median_s_pred)))\n",
        "print('')\n",
        "print ('XGBOOST')\n",
        "print('AUC score: %.3f' % (median_xgb_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymedianv_test, median_x_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymedianv_test, median_x_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymedianv_test, median_x_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymedian_test, median_x_pred)))\n",
        "print('')\n",
        "print ('RANDOM FOREST')\n",
        "print('AUC score: %.3f' % (median_rf_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymedian_test, median_rf_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymedian_test, median_rf_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymedian_test, median_rf_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymedian_test, median_rf_pred)))\n",
        "print('')\n",
        "print('')\n",
        "print('')\n",
        "print ('KNN_1.0 with hist_norm')\n",
        "print ('LOGISTIC REGRESSION')\n",
        "print('AUC score: %.3f' % (knn1_lr_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn1_test, knn1_lr_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn1_test, knn1_lr_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn1_test, knn1_lr_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn1_test, knn1_lr_pred)))\n",
        "print('')\n",
        "print ('SVM')\n",
        "print('AUC score: %.3f' % (knn1_svm_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn1_test, knn1_s_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn1_test, knn1_s_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn1_test, knn1_s_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn1_test, knn1_s_pred)))\n",
        "print('')\n",
        "print ('XGBOOST')\n",
        "print('AUC score: %.3f' % (knn1_xgb_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn1v_test, knn1_x_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn1v_test, knn1_x_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn1v_test, knn1_x_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn1v_test, knn1_x_pred)))\n",
        "print('')\n",
        "print ('RANDOM FOREST')\n",
        "print('AUC score: %.3f' % (knn1_rf_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn1_test, knn1_rf_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn1_test, knn1_rf_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn1_test, knn1_rf_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn1_test, knn1_rf_pred)))\n",
        "print('')\n",
        "print('')\n",
        "print('')\n",
        "print ('KNN_2.0 with hist_norm')\n",
        "print ('LOGISTIC REGRESSION')\n",
        "print('AUC score: %.3f' % (knn2_lr_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn2_test, knn2_lr_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn2_test, knn2_lr_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn2_test, knn2_lr_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn2_test, knn2_lr_pred)))\n",
        "print('')\n",
        "print ('SVM')\n",
        "print('AUC score: %.3f' % (knn2_svm_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn2_test, knn2_s_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn2_test, knn2_s_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn2_test, knn2_s_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn2_test, knn2_s_pred)))\n",
        "print('')\n",
        "print ('XGBOOST')\n",
        "print('AUC score: %.3f' % (knn2_xgb_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn2v_test, knn2_x_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn2v_test, knn2_x_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn2v_test, knn2_x_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn2v_test, knn2_x_pred)))\n",
        "print('')\n",
        "print ('RANDOM FOREST')\n",
        "print('AUC score: %.3f' % (knn2_rf_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn2_test, knn2_rf_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn2_test, knn2_rf_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn2_test, knn2_rf_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn2_test, knn2_rf_pred)))\n",
        "print('')\n",
        "print('')\n",
        "print('')\n",
        "print ('KNN scaled')\n",
        "print ('LOGISTIC REGRESSION')\n",
        "print('AUC score: %.3f' % (knnsc_lr_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknnsc_test, knnsc_lr_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknnsc_test, knnsc_lr_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknnsc_test, knnsc_lr_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknnsc_test, knnsc_lr_pred)))\n",
        "print('')\n",
        "print ('SVM')\n",
        "print('AUC score: %.3f' % (knnsc_svm_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknnsc_test, knnsc_s_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknnsc_test, knnsc_s_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknnsc_test, knnsc_s_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknnsc_test, knnsc_s_pred)))\n",
        "print('')\n",
        "print ('XGBOOST')\n",
        "print('AUC score: %.3f' % (knnsc_xgb_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknnsc_test, knnsc_x_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknnsc_test, knnsc_x_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknnsc_test, knnsc_x_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknnsc_test, knnsc_x_pred)))\n",
        "print('')\n",
        "print ('RANDOM FOREST')\n",
        "print('AUC score: %.3f' % (knnsc_rf_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknnsc_test, knnsc_rf_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknnsc_test, knnsc_rf_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknnsc_test, knnsc_rf_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknnsc_test, knnsc_rf_pred)))\n",
        "print('')\n",
        "print('')\n",
        "print('')\n",
        "print ('MEAN scaled')\n",
        "print ('LOGISTIC REGRESSION')\n",
        "print('AUC score: %.3f' % (meansc_lr_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymeansc_test, meansc_lr_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymeansc_test, meansc_lr_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymeansc_test, meansc_lr_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymeansc_test, meansc_lr_pred)))\n",
        "print('')\n",
        "print ('SVM')\n",
        "print('AUC score: %.3f' % (meansc_svm_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymeansc_test, meansc_s_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymeansc_test, meansc_s_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymeansc_test, meansc_s_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymeansc_test, meansc_s_pred)))\n",
        "print('')\n",
        "print ('XGBOOST')\n",
        "print('AUC score: %.3f' % (meansc_xgb_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymeansc_test, meansc_x_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymeansc_test, meansc_x_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymeansc_test, meansc_x_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymeansc_test, meansc_x_pred)))\n",
        "print('')\n",
        "print ('RANDOM FOREST')\n",
        "print('AUC score: %.3f' % (meansc_rf_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymeansc_test, meansc_rf_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymeansc_test, meansc_rf_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymeansc_test, meansc_rf_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymeansc_test, meansc_rf_pred)))\n",
        "print('')\n",
        "print('')\n",
        "print('')\n",
        "print ('MEDIAN scaled')\n",
        "print ('LOGISTIC REGRESSION')\n",
        "print('AUC score: %.3f' % (mediansc_lr_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymediansc_test, mediansc_lr_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymediansc_test, mediansc_lr_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymediansc_test, mediansc_lr_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymediansc_test, mediansc_lr_pred)))\n",
        "print('')\n",
        "print ('SVM')\n",
        "print('AUC score: %.3f' % (mediansc_svm_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymediansc_test, mediansc_s_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymediansc_test, mediansc_s_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymediansc_test, mediansc_s_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymediansc_test, mediansc_s_pred)))\n",
        "print('')\n",
        "print ('XGBOOST')\n",
        "print('AUC score: %.3f' % (mediansc_xgb_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymediansc_test, mediansc_x_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymediansc_test, mediansc_x_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymediansc_test, mediansc_x_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymediansc_test, mediansc_x_pred)))\n",
        "print('')\n",
        "print ('RANDOM FOREST')\n",
        "print('AUC score: %.3f' % (mediansc_rf_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(ymediansc_test, mediansc_rf_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(ymediansc_test, mediansc_rf_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(ymediansc_test, mediansc_rf_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(ymediansc_test, mediansc_rf_pred)))\n",
        "print('')\n",
        "print('')\n",
        "print('')\n",
        "print ('KNN_1.0 scaled')\n",
        "print ('LOGISTIC REGRESSION')\n",
        "print('AUC score: %.3f' % (knn1sc_lr_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn1sc_test, knn1sc_lr_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn1sc_test, knn1sc_lr_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn1sc_test, knn1sc_lr_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn1sc_test, knn1sc_lr_pred)))\n",
        "print('')\n",
        "print ('SVM')\n",
        "print('AUC score: %.3f' % (knn1sc_svm_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn1sc_test, knn1sc_s_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn1sc_test, knn1sc_s_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn1sc_test, knn1sc_s_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn1sc_test, knn1sc_s_pred)))\n",
        "print('')\n",
        "print ('XGBOOST')\n",
        "print('AUC score: %.3f' % (knn1sc_xgb_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn1sc_test, knn1sc_x_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn1sc_test, knn1sc_x_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn1sc_test, knn1sc_x_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn1sc_test, knn1sc_x_pred)))\n",
        "print('')\n",
        "print ('RANDOM FOREST')\n",
        "print('AUC score: %.3f' % (knn1sc_rf_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn1sc_test, knn1sc_rf_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn1sc_test, knn1sc_rf_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn1sc_test, knn1sc_rf_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn1sc_test, knn1sc_rf_pred)))\n",
        "print('')\n",
        "print('')\n",
        "print('')\n",
        "print ('KNN_2.0 scaled')\n",
        "print ('LOGISTIC REGRESSION')\n",
        "print('AUC score: %.3f' % (knn2sc_lr_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn2sc_test, knn2sc_lr_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn2sc_test, knn2sc_lr_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn2sc_test, knn2sc_lr_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn2sc_test, knn2sc_lr_pred)))\n",
        "print('')\n",
        "print ('SVM')\n",
        "print('AUC score: %.3f' % (knn2sc_svm_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn2sc_test, knn2sc_s_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn2sc_test, knn2sc_s_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn2sc_test, knn2sc_s_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn2sc_test, knn2sc_s_pred)))\n",
        "print('')\n",
        "print ('XGBOOST')\n",
        "print('AUC score: %.3f' % (knn2sc_xgb_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn2sc_test, knn2sc_x_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn2sc_test, knn2sc_x_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn2sc_test, knn2sc_x_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn2sc_test, knn2sc_x_pred)))\n",
        "print('')\n",
        "print ('RANDOM FOREST')\n",
        "print('AUC score: %.3f' % (knn2sc_rf_auc))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(yknn2sc_test, knn2sc_rf_pred)))\n",
        "print('Recall Score: {:.2f}'.format(recall_score(yknn2sc_test, knn2sc_rf_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(yknn2sc_test, knn2sc_rf_pred,zero_division=1)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(yknn2sc_test, knn2sc_rf_pred)))\n",
        "# summarize scores\n",
        "# print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
        "# print('SVM: ROC AUC=%.3f' % (svm_auc))\n",
        "# print('XGBoost: ROC AUC=%.3f' % (xgb_auc))\n",
        "# print('Random Forest: ROC AUC=%.3f' % (rf_auc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNN with hist_norm\n",
            "LOGISTIC REGRESSION\n",
            "AUC score: 0.896\n",
            "Accuracy Score: 0.98\n",
            "Recall Score: 0.00\n",
            "Precision Score: 1.00\n",
            "F1 Score: 0.00\n",
            "\n",
            "SVM\n",
            "AUC score: 0.585\n",
            "Accuracy Score: 0.98\n",
            "Recall Score: 0.00\n",
            "Precision Score: 1.00\n",
            "F1 Score: 0.00\n",
            "\n",
            "XGBOOST\n",
            "AUC score: 0.491\n",
            "Accuracy Score: 0.98\n",
            "Recall Score: 0.00\n",
            "Precision Score: 1.00\n",
            "F1 Score: 0.00\n",
            "\n",
            "RANDOM FOREST\n",
            "AUC score: 0.640\n",
            "Accuracy Score: 0.98\n",
            "Recall Score: 0.00\n",
            "Precision Score: 1.00\n",
            "F1 Score: 0.00\n",
            "\n",
            "\n",
            "\n",
            "MEAN with hist_norm\n",
            "LOGISTIC REGRESSION\n",
            "AUC score: 0.896\n",
            "Accuracy Score: 0.98\n",
            "Recall Score: 0.00\n",
            "Precision Score: 1.00\n",
            "F1 Score: 0.00\n",
            "\n",
            "SVM\n",
            "AUC score: 0.585\n",
            "Accuracy Score: 0.98\n",
            "Recall Score: 0.00\n",
            "Precision Score: 1.00\n",
            "F1 Score: 0.00\n",
            "\n",
            "XGBOOST\n",
            "AUC score: 0.491\n",
            "Accuracy Score: 0.98\n",
            "Recall Score: 0.00\n",
            "Precision Score: 1.00\n",
            "F1 Score: 0.00\n",
            "\n",
            "RANDOM FOREST\n",
            "AUC score: 0.640\n",
            "Accuracy Score: 0.98\n",
            "Recall Score: 0.00\n",
            "Precision Score: 1.00\n",
            "F1 Score: 0.00\n",
            "\n",
            "\n",
            "\n",
            "MEDIAN with hist_norm\n",
            "LOGISTIC REGRESSION\n",
            "AUC score: 0.896\n",
            "Accuracy Score: 0.98\n",
            "Recall Score: 0.00\n",
            "Precision Score: 1.00\n",
            "F1 Score: 0.00\n",
            "\n",
            "SVM\n",
            "AUC score: 0.584\n",
            "Accuracy Score: 0.98\n",
            "Recall Score: 0.00\n",
            "Precision Score: 1.00\n",
            "F1 Score: 0.00\n",
            "\n",
            "XGBOOST\n",
            "AUC score: 0.492\n",
            "Accuracy Score: 0.98\n",
            "Recall Score: 0.00\n",
            "Precision Score: 1.00\n",
            "F1 Score: 0.00\n",
            "\n",
            "RANDOM FOREST\n",
            "AUC score: 0.638\n",
            "Accuracy Score: 0.98\n",
            "Recall Score: 0.00\n",
            "Precision Score: 1.00\n",
            "F1 Score: 0.00\n",
            "\n",
            "\n",
            "\n",
            "KNN_1.0 with hist_norm\n",
            "LOGISTIC REGRESSION\n",
            "AUC score: 0.895\n",
            "Accuracy Score: 0.98\n",
            "Recall Score: 0.00\n",
            "Precision Score: 1.00\n",
            "F1 Score: 0.00\n",
            "\n",
            "SVM\n",
            "AUC score: 0.585\n",
            "Accuracy Score: 0.98\n",
            "Recall Score: 0.00\n",
            "Precision Score: 1.00\n",
            "F1 Score: 0.00\n",
            "\n",
            "XGBOOST\n",
            "AUC score: 0.489\n",
            "Accuracy Score: 0.98\n",
            "Recall Score: 0.00\n",
            "Precision Score: 1.00\n",
            "F1 Score: 0.00\n",
            "\n",
            "RANDOM FOREST\n",
            "AUC score: 0.635\n",
            "Accuracy Score: 0.98\n",
            "Recall Score: 0.00\n",
            "Precision Score: 1.00\n",
            "F1 Score: 0.00\n",
            "\n",
            "\n",
            "\n",
            "KNN_2.0 with hist_norm\n",
            "LOGISTIC REGRESSION\n",
            "AUC score: 0.896\n",
            "Accuracy Score: 0.98\n",
            "Recall Score: 0.00\n",
            "Precision Score: 1.00\n",
            "F1 Score: 0.00\n",
            "\n",
            "SVM\n",
            "AUC score: 0.585\n",
            "Accuracy Score: 0.98\n",
            "Recall Score: 0.00\n",
            "Precision Score: 1.00\n",
            "F1 Score: 0.00\n",
            "\n",
            "XGBOOST\n",
            "AUC score: 0.491\n",
            "Accuracy Score: 0.98\n",
            "Recall Score: 0.00\n",
            "Precision Score: 1.00\n",
            "F1 Score: 0.00\n",
            "\n",
            "RANDOM FOREST\n",
            "AUC score: 0.640\n",
            "Accuracy Score: 0.98\n",
            "Recall Score: 0.00\n",
            "Precision Score: 1.00\n",
            "F1 Score: 0.00\n",
            "\n",
            "\n",
            "\n",
            "KNN scaled\n",
            "LOGISTIC REGRESSION\n",
            "AUC score: 0.952\n",
            "Accuracy Score: 0.99\n",
            "Recall Score: 0.29\n",
            "Precision Score: 0.77\n",
            "F1 Score: 0.42\n",
            "\n",
            "SVM\n",
            "AUC score: 0.921\n",
            "Accuracy Score: 0.99\n",
            "Recall Score: 0.40\n",
            "Precision Score: 0.96\n",
            "F1 Score: 0.57\n",
            "\n",
            "XGBOOST\n",
            "AUC score: 0.980\n",
            "Accuracy Score: 0.99\n",
            "Recall Score: 0.57\n",
            "Precision Score: 0.84\n",
            "F1 Score: 0.68\n",
            "\n",
            "RANDOM FOREST\n",
            "AUC score: 0.968\n",
            "Accuracy Score: 0.99\n",
            "Recall Score: 0.55\n",
            "Precision Score: 0.96\n",
            "F1 Score: 0.70\n",
            "\n",
            "\n",
            "\n",
            "MEAN scaled\n",
            "LOGISTIC REGRESSION\n",
            "AUC score: 0.952\n",
            "Accuracy Score: 0.99\n",
            "Recall Score: 0.29\n",
            "Precision Score: 0.77\n",
            "F1 Score: 0.42\n",
            "\n",
            "SVM\n",
            "AUC score: 0.920\n",
            "Accuracy Score: 0.99\n",
            "Recall Score: 0.40\n",
            "Precision Score: 0.96\n",
            "F1 Score: 0.57\n",
            "\n",
            "XGBOOST\n",
            "AUC score: 0.982\n",
            "Accuracy Score: 0.99\n",
            "Recall Score: 0.53\n",
            "Precision Score: 0.89\n",
            "F1 Score: 0.66\n",
            "\n",
            "RANDOM FOREST\n",
            "AUC score: 0.981\n",
            "Accuracy Score: 0.99\n",
            "Recall Score: 0.56\n",
            "Precision Score: 0.97\n",
            "F1 Score: 0.71\n",
            "\n",
            "\n",
            "\n",
            "MEDIAN scaled\n",
            "LOGISTIC REGRESSION\n",
            "AUC score: 0.951\n",
            "Accuracy Score: 0.99\n",
            "Recall Score: 0.29\n",
            "Precision Score: 0.77\n",
            "F1 Score: 0.42\n",
            "\n",
            "SVM\n",
            "AUC score: 0.922\n",
            "Accuracy Score: 0.99\n",
            "Recall Score: 0.40\n",
            "Precision Score: 0.96\n",
            "F1 Score: 0.57\n",
            "\n",
            "XGBOOST\n",
            "AUC score: 0.971\n",
            "Accuracy Score: 0.98\n",
            "Recall Score: 0.72\n",
            "Precision Score: 0.39\n",
            "F1 Score: 0.51\n",
            "\n",
            "RANDOM FOREST\n",
            "AUC score: 0.967\n",
            "Accuracy Score: 0.99\n",
            "Recall Score: 0.58\n",
            "Precision Score: 0.75\n",
            "F1 Score: 0.65\n",
            "\n",
            "\n",
            "\n",
            "KNN_1.0 scaled\n",
            "LOGISTIC REGRESSION\n",
            "AUC score: 0.949\n",
            "Accuracy Score: 0.99\n",
            "Recall Score: 0.25\n",
            "Precision Score: 0.77\n",
            "F1 Score: 0.38\n",
            "\n",
            "SVM\n",
            "AUC score: 0.907\n",
            "Accuracy Score: 0.99\n",
            "Recall Score: 0.34\n",
            "Precision Score: 0.96\n",
            "F1 Score: 0.51\n",
            "\n",
            "XGBOOST\n",
            "AUC score: 0.965\n",
            "Accuracy Score: 0.99\n",
            "Recall Score: 0.55\n",
            "Precision Score: 0.77\n",
            "F1 Score: 0.64\n",
            "\n",
            "RANDOM FOREST\n",
            "AUC score: 0.963\n",
            "Accuracy Score: 0.99\n",
            "Recall Score: 0.39\n",
            "Precision Score: 0.95\n",
            "F1 Score: 0.56\n",
            "\n",
            "\n",
            "\n",
            "KNN_2.0 scaled\n",
            "LOGISTIC REGRESSION\n",
            "AUC score: 0.952\n",
            "Accuracy Score: 0.99\n",
            "Recall Score: 0.29\n",
            "Precision Score: 0.77\n",
            "F1 Score: 0.42\n",
            "\n",
            "SVM\n",
            "AUC score: 0.920\n",
            "Accuracy Score: 0.99\n",
            "Recall Score: 0.40\n",
            "Precision Score: 0.96\n",
            "F1 Score: 0.57\n",
            "\n",
            "XGBOOST\n",
            "AUC score: 0.982\n",
            "Accuracy Score: 0.99\n",
            "Recall Score: 0.53\n",
            "Precision Score: 0.89\n",
            "F1 Score: 0.66\n",
            "\n",
            "RANDOM FOREST\n",
            "AUC score: 0.981\n",
            "Accuracy Score: 0.99\n",
            "Recall Score: 0.56\n",
            "Precision Score: 0.97\n",
            "F1 Score: 0.71\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}